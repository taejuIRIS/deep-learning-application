### 1. 딥러닝과 머신러닝의 차이점

- *머신러닝(Machine Learning)**은 특징 추출 후 학습을 통해 규칙을 파악하는 반면, **딥러닝(Deep Learning)**은 특징 추출과 학습을 동시에 수행합니다.
- 머신러닝의 경우 데이터 입력과 출력 사이의 규칙을 모델이 학습합니다.

### 2. 레이블 인코딩 및 회귀

- **딥러닝**에서 레이블은 **원-핫 인코딩(one-hot encoding)** 방식으로 표현됩니다. 회귀에서는 ReLU 활성화 함수를 주로 사용하며, 예제 코드에서는 `Adam` 옵티마이저와 `categorical_crossentropy` 손실 함수를 사용합니다.
- **머신러닝 회귀**에서는 uci repository 데이터를 자주 사용하며, 이상치 확인, 타겟 레이블 인코딩 등의 전처리가 필요합니다.

### 3. 차원의 저주

- 특징(feature)이 지나치게 많으면 모델이 패턴을 파악하기 어려워져 차원의 저주(curse of dimensionality)가 발생할 수 있습니다. 이를 해결하기 위해 PCA, 상관계수 확인 등의 **차원 축소(dimensionality reduction)** 방법이 사용됩니다.

### 4. CNN (Convolutional Neural Network)

- CNN은 이미지와 같은 **공간적 정보** 학습을 위해 사용됩니다. 필터를 통한 **국소적 특징 추출**이 가능하며, 풀링(pooling)을 통해 정보 요약 및 이동에 대한 내성을 높입니다.
- **특성 수 과다**로 모델 학습 방해 시:
- `heatmap`을 이용한 상관분석으로 특성 선택.
- PCA 등 차원 축소 기법 활용.

### 5. RNN (Recurrent Neural Network)와 LSTM

- **RNN**은 시계열 데이터와 같이 이전 시점 정보를 반영하는 모델로, 순환 구조를 통해 이전 입력의 영향을 받아 다음 출력을 예측합니다.
    - **RNN 한계**: 시계열 패턴 반영은 가능하나, 시퀀스 길어질 경우 기울기 소실 문제 발생.
- *LSTM (Long Short-Term Memory)**는 RNN의 단점을 개선한 모델로, 중요 정보를 기억하는 셀 상태(cell state)를 도입하여 장기 의존성을 효과적으로 학습합니다.
    - **LSTM**: RNN의 단점을 보완해, 중요한 정보만 **cell state**로 유지하여 기울기 소실 문제 해결.
        - **게이트 구조**: forget, input, output 게이트를 통해 정보 보존 및 업데이트.

### 6. 매니폴드 학습 (Manifold Learning)

- 고차원 데이터는 분석이 어려움 -> 저차원으로 축소하여 간편하게 분석.
- **매니폴드 가정**: 고차원 데이터가 저차원에 근접해 있다고 가정.
- 예: 스위스 롤, PCA 등.

### 7. PCA 및 t-SNE

- **PCA**: 학습 데이터의 분산이 최대가 되도록 주요 축을 찾는 방법.
- **t-SNE**: 고차원 데이터를 저차원에서 시각화하는 또 다른 방법.

### 8. 딥러닝 기본 요소

- **필수 요소**: 옵티마이저, 손실 함수, forward/back propagation, one-hot 인코딩.
- **Dense Layer**: FCNN (완전 연결 신경망)으로도 부름.
- **모델 복잡도 증가 시 단점**: 레이어가 깊어지면 기울기 소실 문제 발생.
    - **해결법**: ResNet에서 도입한 **skip connection**(단축 연결).

### 9. CNN (Convolutional Neural Network) 기본

- **CNN 사용 이유**: 공간적 특징을 추출하여 부분적 학습을 통해 성능 개선.
- **핵심 개념**: 필터와 스트라이드, 패딩으로 부분 정보 추출 -> `Convolution -> Pooling` 단계를 거침.
- **Pooling 장점**: 데이터 이동에 강건, 정보 요약.

### 10. 네트워크 요약

- **DNN**: 공간적 특징 미반영.
- **CNN**: 공간 정보 학습 가능, 하지만 시계열 반영 어려움.
- **RNN**: 문맥 반영 가능하지만 기울기 소실 문제.
- **LSTM**: RNN의 문제 개선, 단 길이가 길어지면 여전히 한계.

### 실습

머신 러닝

- x, y로 나누어서 분류 해야 한다.
- 트레인 하고 xtrain, y train
- 테스트 x test, y test

딥러닝

- 딥러닝은 레이블을 엔코딩 해야 한다. (feature → 인코딩)
- one-hot-encoding
- numpy
- 입력값과 입력층,뉴런수 :feature, 출력값 :
- 대부분 relu를 쓴다.
