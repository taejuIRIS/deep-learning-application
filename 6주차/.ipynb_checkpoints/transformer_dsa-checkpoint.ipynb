{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f252617a",
   "metadata": {},
   "source": [
    "# Transformer를 이용하여 DSA 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0aa4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd12460",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>activity</th>\n",
       "      <th>people</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.975714</td>\n",
       "      <td>8.1605</td>\n",
       "      <td>7.6823</td>\n",
       "      <td>0.014395</td>\n",
       "      <td>0.119981</td>\n",
       "      <td>-0.023319</td>\n",
       "      <td>1.083150</td>\n",
       "      <td>1.1832</td>\n",
       "      <td>0.99744</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.054963</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>6.778722e-07</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.978250</td>\n",
       "      <td>8.1763</td>\n",
       "      <td>7.8472</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.086896</td>\n",
       "      <td>0.552416</td>\n",
       "      <td>1.140865</td>\n",
       "      <td>1.2129</td>\n",
       "      <td>1.05810</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>-0.286918</td>\n",
       "      <td>-0.057268</td>\n",
       "      <td>-0.054945</td>\n",
       "      <td>-0.059589</td>\n",
       "      <td>7.032302e-07</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.347471</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.970894</td>\n",
       "      <td>8.0860</td>\n",
       "      <td>7.8470</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>1.140962</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>1.07960</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>-0.057068</td>\n",
       "      <td>-0.054711</td>\n",
       "      <td>-0.059065</td>\n",
       "      <td>6.268222e-07</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.045579</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.938412</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>7.6901</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>0.061343</td>\n",
       "      <td>-0.231914</td>\n",
       "      <td>1.165260</td>\n",
       "      <td>1.3170</td>\n",
       "      <td>1.07870</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>-0.056422</td>\n",
       "      <td>-0.053670</td>\n",
       "      <td>-0.058310</td>\n",
       "      <td>8.011245e-07</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.908930</td>\n",
       "      <td>8.1305</td>\n",
       "      <td>7.8322</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>2.042285</td>\n",
       "      <td>1.187504</td>\n",
       "      <td>1.2574</td>\n",
       "      <td>1.09450</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>-0.148229</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>-0.053313</td>\n",
       "      <td>-0.057815</td>\n",
       "      <td>6.853423e-07</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.258429</td>\n",
       "      <td>sitting</td>\n",
       "      <td>p1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>8.280854</td>\n",
       "      <td>34.1980</td>\n",
       "      <td>-2.9038</td>\n",
       "      <td>28.080803</td>\n",
       "      <td>5.299132</td>\n",
       "      <td>1.350075</td>\n",
       "      <td>-1.491537</td>\n",
       "      <td>11.2240</td>\n",
       "      <td>-11.65100</td>\n",
       "      <td>14.670334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200829</td>\n",
       "      <td>-0.040701</td>\n",
       "      <td>0.297666</td>\n",
       "      <td>0.708480</td>\n",
       "      <td>-0.117430</td>\n",
       "      <td>4.135451e-02</td>\n",
       "      <td>0.203358</td>\n",
       "      <td>-0.310022</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>9.591118</td>\n",
       "      <td>51.6970</td>\n",
       "      <td>-3.4129</td>\n",
       "      <td>35.722025</td>\n",
       "      <td>5.976791</td>\n",
       "      <td>2.981144</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>6.9951</td>\n",
       "      <td>-11.76400</td>\n",
       "      <td>5.329897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148745</td>\n",
       "      <td>-0.266377</td>\n",
       "      <td>0.224716</td>\n",
       "      <td>0.554670</td>\n",
       "      <td>-0.250950</td>\n",
       "      <td>3.355704e-02</td>\n",
       "      <td>0.183186</td>\n",
       "      <td>-0.736410</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9117</th>\n",
       "      <td>9.599113</td>\n",
       "      <td>27.9300</td>\n",
       "      <td>-1.0765</td>\n",
       "      <td>48.850886</td>\n",
       "      <td>6.989341</td>\n",
       "      <td>0.449237</td>\n",
       "      <td>-0.728367</td>\n",
       "      <td>3.7801</td>\n",
       "      <td>-8.36910</td>\n",
       "      <td>5.683022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310748</td>\n",
       "      <td>-0.009505</td>\n",
       "      <td>-0.237786</td>\n",
       "      <td>0.088854</td>\n",
       "      <td>-0.477260</td>\n",
       "      <td>2.026107e-02</td>\n",
       "      <td>0.142341</td>\n",
       "      <td>0.668438</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9118</th>\n",
       "      <td>9.692482</td>\n",
       "      <td>72.7820</td>\n",
       "      <td>-2.6734</td>\n",
       "      <td>59.378336</td>\n",
       "      <td>7.705734</td>\n",
       "      <td>4.491114</td>\n",
       "      <td>-0.582724</td>\n",
       "      <td>6.1216</td>\n",
       "      <td>-8.85710</td>\n",
       "      <td>4.162963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156493</td>\n",
       "      <td>0.050624</td>\n",
       "      <td>0.533023</td>\n",
       "      <td>0.677800</td>\n",
       "      <td>0.055941</td>\n",
       "      <td>1.356379e-02</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>-1.482489</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9119</th>\n",
       "      <td>9.380641</td>\n",
       "      <td>45.0090</td>\n",
       "      <td>-3.5938</td>\n",
       "      <td>40.459334</td>\n",
       "      <td>6.360765</td>\n",
       "      <td>1.688626</td>\n",
       "      <td>-0.266325</td>\n",
       "      <td>5.8603</td>\n",
       "      <td>-6.91970</td>\n",
       "      <td>4.017098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229154</td>\n",
       "      <td>-0.342228</td>\n",
       "      <td>0.491919</td>\n",
       "      <td>0.707920</td>\n",
       "      <td>0.251280</td>\n",
       "      <td>9.358254e-03</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>-0.223302</td>\n",
       "      <td>basketBall</td>\n",
       "      <td>p8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9120 rows × 272 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  \\\n",
       "0        7.975714      8.1605      7.6823    0.014395    0.119981   \n",
       "1        7.978250      8.1763      7.8472    0.007551    0.086896   \n",
       "2        7.970894      8.0860      7.8470    0.003092    0.055603   \n",
       "3        7.938412      8.1083      7.6901    0.003763    0.061343   \n",
       "4        7.908930      8.1305      7.8322    0.001741    0.041731   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "9115     8.280854     34.1980     -2.9038   28.080803    5.299132   \n",
       "9116     9.591118     51.6970     -3.4129   35.722025    5.976791   \n",
       "9117     9.599113     27.9300     -1.0765   48.850886    6.989341   \n",
       "9118     9.692482     72.7820     -2.6734   59.378336    7.705734   \n",
       "9119     9.380641     45.0090     -3.5938   40.459334    6.360765   \n",
       "\n",
       "      T_xacc_skew  T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...  \\\n",
       "0       -0.023319     1.083150      1.1832     0.99744    0.002208  ...   \n",
       "1        0.552416     1.140865      1.2129     1.05810    0.000784  ...   \n",
       "2        0.100538     1.140962      1.2128     1.07960    0.000508  ...   \n",
       "3       -0.231914     1.165260      1.3170     1.07870    0.002173  ...   \n",
       "4        2.042285     1.187504      1.2574     1.09450    0.000662  ...   \n",
       "...           ...          ...         ...         ...         ...  ...   \n",
       "9115     1.350075    -1.491537     11.2240   -11.65100   14.670334  ...   \n",
       "9116     2.981144     0.086304      6.9951   -11.76400    5.329897  ...   \n",
       "9117     0.449237    -0.728367      3.7801    -8.36910    5.683022  ...   \n",
       "9118     4.491114    -0.582724      6.1216    -8.85710    4.162963  ...   \n",
       "9119     1.688626    -0.266325      5.8603    -6.91970    4.017098  ...   \n",
       "\n",
       "      LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "0        0.000792      0.177075     -0.057119    -0.054963    -0.059241   \n",
       "1        0.000860     -0.286918     -0.057268    -0.054945    -0.059589   \n",
       "2        0.000762     -0.134430     -0.057068    -0.054711    -0.059065   \n",
       "3        0.000735      0.021485     -0.056422    -0.053670    -0.058310   \n",
       "4        0.000824     -0.148229     -0.055801    -0.053313    -0.057815   \n",
       "...           ...           ...           ...          ...          ...   \n",
       "9115     0.200829     -0.040701      0.297666     0.708480    -0.117430   \n",
       "9116     0.148745     -0.266377      0.224716     0.554670    -0.250950   \n",
       "9117     0.310748     -0.009505     -0.237786     0.088854    -0.477260   \n",
       "9118     0.156493      0.050624      0.533023     0.677800     0.055941   \n",
       "9119     0.229154     -0.342228      0.491919     0.707920     0.251280   \n",
       "\n",
       "       LL_zmag_var  LL_zmag_std  LL_zmag_skew    activity  people  \n",
       "0     6.778722e-07     0.000823      0.036729     sitting      p1  \n",
       "1     7.032302e-07     0.000839      0.347471     sitting      p1  \n",
       "2     6.268222e-07     0.000792      0.045579     sitting      p1  \n",
       "3     8.011245e-07     0.000895      0.240690     sitting      p1  \n",
       "4     6.853423e-07     0.000828      0.258429     sitting      p1  \n",
       "...            ...          ...           ...         ...     ...  \n",
       "9115  4.135451e-02     0.203358     -0.310022  basketBall      p8  \n",
       "9116  3.355704e-02     0.183186     -0.736410  basketBall      p8  \n",
       "9117  2.026107e-02     0.142341      0.668438  basketBall      p8  \n",
       "9118  1.356379e-02     0.116464     -1.482489  basketBall      p8  \n",
       "9119  9.358254e-03     0.096738     -0.223302  basketBall      p8  \n",
       "\n",
       "[9120 rows x 272 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:/Users/Administrator/dataset/DSA_features.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c15bb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lyingBack    480\n",
       "lyingRigh    480\n",
       "jumping      480\n",
       "Name: activity, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df['activity'].isin(['lyingRigh', 'lyingBack', 'jumping'])]\n",
    "df['activity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0b73d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((480, 272), (960, 272))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abnormal = df[df.activity == 'jumping']\n",
    "normal = df[df.activity.isin(['lyingRigh', 'lyingBack'])]\n",
    "\n",
    "abnormal.shape, normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef5b2a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15168\\3950745939.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['class'] = df['activity'].apply(lambda x: 'normal' if x.startswith('lying') else 'abnormal')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['T_xacc_mean', 'T_xacc_max', 'T_xacc_min', 'T_xacc_var', 'T_xacc_std',\n",
       "       'T_xacc_skew', 'T_yacc_mean', 'T_yacc_max', 'T_yacc_min', 'T_yacc_var',\n",
       "       ...\n",
       "       'LL_ymag_skew', 'LL_zmag_mean', 'LL_zmag_max', 'LL_zmag_min',\n",
       "       'LL_zmag_var', 'LL_zmag_std', 'LL_zmag_skew', 'activity', 'people',\n",
       "       'class'],\n",
       "      dtype='object', length=273)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'] = df['activity'].apply(lambda x: 'normal' if x.startswith('lying') else 'abnormal')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d5ea4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_xacc_mean</th>\n",
       "      <th>T_xacc_max</th>\n",
       "      <th>T_xacc_min</th>\n",
       "      <th>T_xacc_var</th>\n",
       "      <th>T_xacc_std</th>\n",
       "      <th>T_xacc_skew</th>\n",
       "      <th>T_yacc_mean</th>\n",
       "      <th>T_yacc_max</th>\n",
       "      <th>T_yacc_min</th>\n",
       "      <th>T_yacc_var</th>\n",
       "      <th>...</th>\n",
       "      <th>LL_ymag_var</th>\n",
       "      <th>LL_ymag_std</th>\n",
       "      <th>LL_ymag_skew</th>\n",
       "      <th>LL_zmag_mean</th>\n",
       "      <th>LL_zmag_max</th>\n",
       "      <th>LL_zmag_min</th>\n",
       "      <th>LL_zmag_var</th>\n",
       "      <th>LL_zmag_std</th>\n",
       "      <th>LL_zmag_skew</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-4.834646</td>\n",
       "      <td>-4.7185</td>\n",
       "      <td>-4.9049</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.033529</td>\n",
       "      <td>0.632141</td>\n",
       "      <td>-0.501018</td>\n",
       "      <td>-0.41744</td>\n",
       "      <td>-0.59561</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>...</td>\n",
       "      <td>9.725263e-07</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.074676</td>\n",
       "      <td>-0.532664</td>\n",
       "      <td>-0.52993</td>\n",
       "      <td>-0.53521</td>\n",
       "      <td>9.585668e-07</td>\n",
       "      <td>0.000979</td>\n",
       "      <td>-0.193301</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>-4.780810</td>\n",
       "      <td>-4.5850</td>\n",
       "      <td>-4.8833</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.062835</td>\n",
       "      <td>1.052880</td>\n",
       "      <td>-0.480601</td>\n",
       "      <td>-0.40372</td>\n",
       "      <td>-0.63184</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>...</td>\n",
       "      <td>6.211659e-07</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>-0.181526</td>\n",
       "      <td>-0.531169</td>\n",
       "      <td>-0.52940</td>\n",
       "      <td>-0.53365</td>\n",
       "      <td>7.608973e-07</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>-0.372381</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>-4.804400</td>\n",
       "      <td>-4.7037</td>\n",
       "      <td>-4.8755</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.038496</td>\n",
       "      <td>0.735226</td>\n",
       "      <td>-0.493925</td>\n",
       "      <td>-0.42616</td>\n",
       "      <td>-0.59561</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>...</td>\n",
       "      <td>4.579046e-07</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.263115</td>\n",
       "      <td>-0.530569</td>\n",
       "      <td>-0.52873</td>\n",
       "      <td>-0.53222</td>\n",
       "      <td>5.160537e-07</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.185587</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>-4.750563</td>\n",
       "      <td>-4.5696</td>\n",
       "      <td>-4.8977</td>\n",
       "      <td>0.004447</td>\n",
       "      <td>0.066683</td>\n",
       "      <td>0.710263</td>\n",
       "      <td>-0.437358</td>\n",
       "      <td>-0.30877</td>\n",
       "      <td>-0.55225</td>\n",
       "      <td>0.003587</td>\n",
       "      <td>...</td>\n",
       "      <td>4.703523e-07</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>-0.060925</td>\n",
       "      <td>-0.531167</td>\n",
       "      <td>-0.52962</td>\n",
       "      <td>-0.53283</td>\n",
       "      <td>4.975523e-07</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>-0.145321</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>-4.774916</td>\n",
       "      <td>-4.6741</td>\n",
       "      <td>-4.8457</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.032868</td>\n",
       "      <td>0.324779</td>\n",
       "      <td>-0.459456</td>\n",
       "      <td>-0.38900</td>\n",
       "      <td>-0.53714</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>...</td>\n",
       "      <td>5.467316e-07</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.335811</td>\n",
       "      <td>-0.529804</td>\n",
       "      <td>-0.52706</td>\n",
       "      <td>-0.53251</td>\n",
       "      <td>1.292131e-06</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>-0.026271</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     T_xacc_mean  T_xacc_max  T_xacc_min  T_xacc_var  T_xacc_std  T_xacc_skew  \\\n",
       "960    -4.834646     -4.7185     -4.9049    0.001124    0.033529     0.632141   \n",
       "961    -4.780810     -4.5850     -4.8833    0.003948    0.062835     1.052880   \n",
       "962    -4.804400     -4.7037     -4.8755    0.001482    0.038496     0.735226   \n",
       "963    -4.750563     -4.5696     -4.8977    0.004447    0.066683     0.710263   \n",
       "964    -4.774916     -4.6741     -4.8457    0.001080    0.032868     0.324779   \n",
       "\n",
       "     T_yacc_mean  T_yacc_max  T_yacc_min  T_yacc_var  ...   LL_ymag_var  \\\n",
       "960    -0.501018    -0.41744    -0.59561    0.001016  ...  9.725263e-07   \n",
       "961    -0.480601    -0.40372    -0.63184    0.001297  ...  6.211659e-07   \n",
       "962    -0.493925    -0.42616    -0.59561    0.000863  ...  4.579046e-07   \n",
       "963    -0.437358    -0.30877    -0.55225    0.003587  ...  4.703523e-07   \n",
       "964    -0.459456    -0.38900    -0.53714    0.001059  ...  5.467316e-07   \n",
       "\n",
       "     LL_ymag_std  LL_ymag_skew  LL_zmag_mean  LL_zmag_max  LL_zmag_min  \\\n",
       "960     0.000986      0.074676     -0.532664     -0.52993     -0.53521   \n",
       "961     0.000788     -0.181526     -0.531169     -0.52940     -0.53365   \n",
       "962     0.000677     -0.263115     -0.530569     -0.52873     -0.53222   \n",
       "963     0.000686     -0.060925     -0.531167     -0.52962     -0.53283   \n",
       "964     0.000739      0.335811     -0.529804     -0.52706     -0.53251   \n",
       "\n",
       "      LL_zmag_var  LL_zmag_std  LL_zmag_skew   class  \n",
       "960  9.585668e-07     0.000979     -0.193301  normal  \n",
       "961  7.608973e-07     0.000872     -0.372381  normal  \n",
       "962  5.160537e-07     0.000718      0.185587  normal  \n",
       "963  4.975523e-07     0.000705     -0.145321  normal  \n",
       "964  1.292131e-06     0.001137     -0.026271  normal  \n",
       "\n",
       "[5 rows x 271 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.drop(['activity', 'people'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b415c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# normal Train data\n",
    "X_train = normal.drop(['activity', 'people'], axis=1)\n",
    "\n",
    "# mixed test data\n",
    "X_mix = df.iloc[:, :-1].drop(['activity', 'people'], axis=1)\n",
    "y_mix = df.iloc[:, -1]\n",
    "y_mix = le.fit_transform(y_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "497c12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 정규화\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_mix = ss.transform(X_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b39d1c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mix_train, X_min_test, y_mix_train, y_mix_test = train_test_split(\n",
    "    X_mix, y_mix, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92f261cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "X_train = X_mix_train.reshape((X_mix_train.shape[0], X_mix_train.shape[1], 1))\n",
    "X_test = X_min_test.reshape((X_min_test.shape[0], X_min_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "325e9d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1152, 270, 1), (1152,), (288, 270, 1), (288,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_mix_train.shape, X_test.shape, y_mix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2eefb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1cb39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc175c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "\n",
    "    # Attention and Normalization\n",
    "    x = layers.MultiHeadAttention(\n",
    "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "    )(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    # Feed Forward Part\n",
    "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de204af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(input_shape,\n",
    "                head_size,\n",
    "                num_heads,\n",
    "                ff_dim,\n",
    "                num_transformer_blocks,\n",
    "                mlp_units,\n",
    "                dropout=0,\n",
    "                mlp_dropout=0,\n",
    "):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = inputs\n",
    "\n",
    "    for _ in range(num_transformer_blocks):\n",
    "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D(data_format=\"channels_last\")(x)\n",
    "\n",
    "    for dim in mlp_units:\n",
    "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(mlp_dropout)(x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0ff7be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = build_model(\n",
    "    input_shape,\n",
    "    head_size=256,\n",
    "    num_heads=4,\n",
    "    ff_dim=4,\n",
    "    num_transformer_blocks=4,\n",
    "    mlp_units=[128],\n",
    "    mlp_dropout=0.4,\n",
    "    dropout=0.25,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab4621d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                               │                           │                 │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,169</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                               │                           │                 │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ global_average_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │           \u001b[38;5;34m7,169\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                               │                           │                 │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m8\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m5\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │           \u001b[38;5;34m7,169\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m8\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m5\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │           \u001b[38;5;34m7,169\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m8\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m5\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │           \u001b[38;5;34m7,169\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ multi_head_attention_3[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_6         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m8\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m4\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m5\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m2\u001b[0m │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m270\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                               │                           │                 │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m256\u001b[0m │ global_average_pooling1d[\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │             \u001b[38;5;34m129\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,129</span> (113.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,129\u001b[0m (113.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,129</span> (113.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,129\u001b[0m (113.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 3s/step - accuracy: 0.7519 - loss: 1.7167 - val_accuracy: 0.9264 - val_loss: 0.4409\n",
      "Epoch 2/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.8238 - loss: 1.8604 - val_accuracy: 0.9351 - val_loss: 0.4357\n",
      "Epoch 3/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3s/step - accuracy: 0.8426 - loss: 1.5712 - val_accuracy: 0.9524 - val_loss: 0.4308\n",
      "Epoch 4/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3s/step - accuracy: 0.8811 - loss: 1.1065 - val_accuracy: 0.9697 - val_loss: 0.4257\n",
      "Epoch 5/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3s/step - accuracy: 0.9078 - loss: 1.4219 - val_accuracy: 0.9784 - val_loss: 0.4201\n",
      "Epoch 6/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9377 - loss: 0.8729 - val_accuracy: 0.9827 - val_loss: 0.4142\n",
      "Epoch 7/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 5s/step - accuracy: 0.9427 - loss: 0.7389 - val_accuracy: 0.9870 - val_loss: 0.4081\n",
      "Epoch 8/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.9498 - loss: 0.7027 - val_accuracy: 0.9870 - val_loss: 0.4017\n",
      "Epoch 9/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 0.9582 - loss: 0.7246 - val_accuracy: 0.9870 - val_loss: 0.3950\n",
      "Epoch 10/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3s/step - accuracy: 0.9398 - loss: 0.6561 - val_accuracy: 0.9870 - val_loss: 0.3881\n",
      "Epoch 11/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.9739 - loss: 0.5775 - val_accuracy: 0.9870 - val_loss: 0.3810\n",
      "Epoch 12/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.9630 - loss: 0.5700 - val_accuracy: 0.9870 - val_loss: 0.3736\n",
      "Epoch 13/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.9635 - loss: 0.5645 - val_accuracy: 0.9870 - val_loss: 0.3661\n",
      "Epoch 14/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9746 - loss: 0.5336 - val_accuracy: 0.9913 - val_loss: 0.3582\n",
      "Epoch 15/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.9803 - loss: 0.4379 - val_accuracy: 0.9913 - val_loss: 0.3504\n",
      "Epoch 16/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.9749 - loss: 0.4992 - val_accuracy: 0.9913 - val_loss: 0.3423\n",
      "Epoch 17/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 6s/step - accuracy: 0.9735 - loss: 0.5348 - val_accuracy: 0.9913 - val_loss: 0.3339\n",
      "Epoch 18/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 0.9675 - loss: 0.4369 - val_accuracy: 0.9913 - val_loss: 0.3256\n",
      "Epoch 19/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3s/step - accuracy: 0.9815 - loss: 0.4557 - val_accuracy: 0.9913 - val_loss: 0.3169\n",
      "Epoch 20/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3s/step - accuracy: 0.9745 - loss: 0.4482 - val_accuracy: 0.9913 - val_loss: 0.3082\n",
      "Epoch 21/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 3s/step - accuracy: 0.9806 - loss: 0.3992 - val_accuracy: 0.9913 - val_loss: 0.2994\n",
      "Epoch 22/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 0.9845 - loss: 0.3936 - val_accuracy: 0.9913 - val_loss: 0.2907\n",
      "Epoch 23/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - accuracy: 0.9885 - loss: 0.3621 - val_accuracy: 0.9913 - val_loss: 0.2818\n",
      "Epoch 24/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 0.9803 - loss: 0.3274 - val_accuracy: 0.9913 - val_loss: 0.2731\n",
      "Epoch 25/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - accuracy: 0.9757 - loss: 0.4847 - val_accuracy: 0.9913 - val_loss: 0.2642\n",
      "Epoch 26/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 3s/step - accuracy: 0.9836 - loss: 0.2993 - val_accuracy: 0.9913 - val_loss: 0.2553\n",
      "Epoch 27/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3s/step - accuracy: 0.9808 - loss: 0.4879 - val_accuracy: 0.9913 - val_loss: 0.2466\n",
      "Epoch 28/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - accuracy: 0.9881 - loss: 0.2936 - val_accuracy: 0.9913 - val_loss: 0.2380\n",
      "Epoch 29/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - accuracy: 0.9868 - loss: 0.2746 - val_accuracy: 0.9913 - val_loss: 0.2294\n",
      "Epoch 30/30\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 3s/step - accuracy: 0.9792 - loss: 0.3443 - val_accuracy: 0.9913 - val_loss: 0.2209\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'testy_one_hot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15168\\3174201816.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesty_one_hot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'testy_one_hot' is not defined"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_mix_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7d98e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHFCAYAAAAe+pb9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjkklEQVR4nO3deVhTV/4G8PcGSNiD7CAIuKGgIq6A2taquLd2k+ni0kXrtJ1qrdPW7tuU1l9t1VptO7VlnE5dOrhN1bpURa24g1rFBTcQQWQNOyS5vz8CkcgiYOAm5P08z33g3pzcfJNJh9dzzz1HEEVRBBEREZEFkkldABEREZFUGISIiIjIYjEIERERkcViECIiIiKLxSBEREREFotBiIiIiCwWgxARERFZLAYhIiIislgMQkRERGSxGISIqF24cuUKBEFAXFxcs5+7Z88eCIKAPXv2GKUdEZkPBiEiIiKyWAxCREREZLEYhIjIKN5//30IgoCTJ0/iscceg1KphKurK+bOnQu1Wo1z585hzJgxcHJyQmBgIBYsWFDnHGlpaXjqqafg6ekJhUKBnj17YuHChdBqtQbtrl+/jsmTJ8PJyQlKpRIxMTHIysqqt66jR4/igQcegKurK2xtbREeHo61a9ca9b1v2rQJkZGRsLe3h5OTE0aNGoXExESDNjdv3sTMmTPh7+8PhUIBDw8PDBkyBDt37tS3SUpKwoQJE/Tv39fXF+PHj8e1a9eMWi8R3WItdQFE1L5MnjwZTz31FJ5//nns2LEDCxYsQFVVFXbu3IkXXngB8+bNw88//4zXX38dXbt2xcMPPwxAFxSioqJQWVmJjz76CIGBgfj1118xb948XLx4EcuWLQMAlJWVYeTIkbh+/TpiY2PRvXt3bN68GTExMXVq2b17N8aMGYPBgwfjm2++gVKpxOrVqxETE4PS0lJMnz79rt/vzz//jCeffBLR0dFYtWoVKioqsGDBAtx33334/fffMXToUADAlClTcPz4cfzjH/9A9+7dUVBQgOPHjyM3NxcAUFJSglGjRiEoKAhff/01vLy8kJWVhd27d6OoqOiu6ySiBohEREbw3nvviQDEhQsXGhzv27evCEBct26d/lhVVZXo4eEhPvzww/pjb7zxhghAPHTokMHz//rXv4qCIIjnzp0TRVEUly9fLgIQN27caNBuxowZIgDxxx9/1B/r0aOHGB4eLlZVVRm0nTBhgujj4yNqNBpRFEVx9+7dIgBx9+7djb7H29tpNBrR19dX7N27t/5coiiKRUVFoqenpxgVFaU/5ujoKM6ZM6fBcx89elQEIG7YsKHRGojIuHhpjIiMasKECQb7PXv2hCAIGDt2rP6YtbU1unbtiqtXr+qP7dq1CyEhIRg0aJDB86dPnw5RFLFr1y4Aul4eJycnPPDAAwbtnnjiCYP91NRUnD17Fk8++SQAQK1W67dx48YhMzMT586du6v3eu7cOVy/fh1TpkyBTHbr/04dHR3xyCOP4ODBgygtLQUADBo0CHFxcfj4449x8OBBVFVVGZyra9eu6NChA15//XV88803OHPmzF3VRkRNwyBEREbl6upqsC+Xy2Fvbw9bW9s6x8vLy/X7ubm58PHxqXM+X19f/eM1P728vOq08/b2Nti/ceMGAGDevHmwsbEx2F544QUAQE5OTnPfnoGamhqqW6vVIj8/HwCwZs0aTJs2Dd9//z0iIyPh6uqKqVOn6sc2KZVKJCQkoG/fvnjzzTcRGhoKX19fvPfee3VCExEZD8cIEZFJcHNzQ2ZmZp3j169fBwC4u7vr2x0+fLhOu9sHS9e0nz9/vn4c0u2Cg4PvumYADdYtk8nQoUMHfT2LFi3CokWLkJaWhk2bNuGNN95AdnY2fvvtNwBA7969sXr1aoiiiJMnTyIuLg4ffvgh7Ozs8MYbb9xVrURUP/YIEZFJGDFiBM6cOYPjx48bHF+5ciUEQcDw4cMBAMOHD0dRURE2bdpk0O7nn3822A8ODka3bt1w4sQJDBgwoN7NycnprmoODg5Gx44d8fPPP0MURf3xkpISxMfH6+8ku12nTp3w0ksvYdSoUXXeLwAIgoCwsDB8+eWXcHFxqbcNERkHe4SIyCS88sorWLlyJcaPH48PP/wQAQEB2Lx5M5YtW4a//vWv6N69OwBg6tSp+PLLLzF16lT84x//QLdu3bBlyxZs27atzjm//fZbjB07FqNHj8b06dPRsWNH5OXlISUlBcePH8cvv/xyVzXLZDIsWLAATz75JCZMmIDnn38eFRUV+L//+z8UFBTg008/BQAUFhZi+PDheOKJJ9CjRw84OTnhyJEj+O233/S9Vb/++iuWLVuGSZMmoXPnzhBFEevWrUNBQQFGjRp1V3USUcMYhIjIJHh4eODAgQOYP38+5s+fD5VKhc6dO2PBggWYO3euvp29vT127dqF2bNn44033oAgCIiOjsbq1asRFRVlcM7hw4fj8OHD+Mc//oE5c+YgPz8fbm5uCAkJweTJk41S9xNPPAEHBwfExsYiJiYGVlZWiIiIwO7du/X12NraYvDgwfj3v/+NK1euoKqqCp06dcLrr7+O1157DQDQrVs3uLi4YMGCBbh+/TrkcjmCg4MRFxeHadOmGaVWIqpLEGv35xIRERFZEI4RIiIiIovFIEREREQWi0GIiIiILBaDEBEREVksBiEiIiKyWAxCREREZLE4j1A9tFotrl+/DicnJwiCIHU5RERE1ASiKKKoqAi+vr4GCyE3hkGoHtevX4e/v7/UZRAREVELpKenw8/Pr0ltGYTqUbP+UHp6OpydnSWuhoiIiJpCpVLB39+/WesIMgjVo+ZymLOzM4MQERGRmWnOsBYOliYiIiKLxSBEREREFotBiIiIiCwWxwgRERG1MY1Gg6qqKqnLMEtyubzJt8Y3BYMQERFRGxFFEVlZWSgoKJC6FLMlk8kQFBQEuVxulPMxCBEREbWRmhDk6ekJe3t7TtrbTDUTHmdmZqJTp05G+fwkDUKxsbFYt24dzp49Czs7O0RFReGzzz5DcHBwo89LSEjA3Llzcfr0afj6+uK1117DrFmzDNrEx8fjnXfewcWLF9GlSxf84x//wEMPPdSab4eIiKhBGo1GH4Lc3NykLsdseXh44Pr161Cr1bCxsbnr80k6WDohIQEvvvgiDh48iB07dkCtViM6OholJSUNPufy5csYN24chg0bhqSkJLz55pt4+eWXER8fr2+TmJiImJgYTJkyBSdOnMCUKVMwefJkHDp0qC3eFhERUR01Y4Ls7e0lrsS81VwS02g0RjmfIIqiaJQzGcHNmzfh6emJhIQE3HPPPfW2ef3117Fp0yakpKToj82aNQsnTpxAYmIiACAmJgYqlQpbt27VtxkzZgw6dOiAVatW3bEOlUoFpVKJwsJCTqhIRERGUV5ejsuXLyMoKAi2trZSl2O2GvscW/L326Runy8sLAQAuLq6NtgmMTER0dHRBsdGjx6No0eP6tN2Q20OHDhQ7zkrKiqgUqkMNiIiImr/TCYIiaKIuXPnYujQoejVq1eD7bKysuDl5WVwzMvLC2q1Gjk5OY22ycrKqvecsbGxUCqV+o0LrhIREbWOwMBALFq0SOoy9EwmCL300ks4efJkky5d3T5KvObqXu3j9bVpaHT5/PnzUVhYqN/S09ObWz4REVG7dd9992HOnDlGOdeRI0cwc+ZMo5zLGEzi9vm//e1v2LRpE/bu3Qs/P79G23p7e9fp2cnOzoa1tbV+FH5DbW7vJaqhUCigUCju4h00XXpeKcqqNOju1fSVcYmIiEyZKIrQaDSwtr5zrPDw8GiDippO0h4hURTx0ksvYd26ddi1axeCgoLu+JzIyEjs2LHD4Nj27dsxYMAA/W10DbWJiooyXvEtsPVUJkYsTMDr8SdhQmPUiYiIGjR9+nQkJCRg8eLFEAQBgiAgLi4OgiBg27ZtGDBgABQKBfbt24eLFy/iwQcfhJeXFxwdHTFw4EDs3LnT4Hy3XxoTBAHff/89HnroIdjb26Nbt27YtGlTm70/SYPQiy++iJ9++gk///wznJyckJWVhaysLJSVlenbzJ8/H1OnTtXvz5o1C1evXsXcuXORkpKCH374AStWrMC8efP0bWbPno3t27fjs88+w9mzZ/HZZ59h586dRuvWa6n+AR1gbSUgKa0Am09lSloLERFJSxRFlFaqJdma84/xxYsXIzIyEjNmzEBmZiYyMzP1Y2lfe+01xMbGIiUlBX369EFxcTHGjRuHnTt3IikpCaNHj8bEiRORlpbW6Gt88MEHmDx5Mk6ePIlx48bhySefRF5e3l19vk0l6aWx5cuXA9Bde6ztxx9/xPTp0wEAmZmZBh9gUFAQtmzZgldeeQVff/01fH19sWTJEjzyyCP6NlFRUVi9ejXefvttvPPOO+jSpQvWrFmDwYMHt/p7aoynsy2ev6cLvtx5Hp/9dhajQrygsLaStCYiIpJGWZUGIe9uk+S1z3w4GvbypkUApVIJuVwOe3t7eHt7AwDOnj0LAPjwww8xatQofVs3NzeEhYXp9z/++GOsX78emzZtwksvvdTga0yfPh2PP/44AOCTTz7BV199hcOHD2PMmDHNfm/NJWkQakoijYuLq3Ps3nvvxfHjxxt93qOPPopHH320paW1mhn3BOE/h64iPa8M/068iueGdZa6JCIiohYZMGCAwX5JSQk++OAD/Prrr/rZn8vKyu7YI9SnTx/97w4ODnByckJ2dnar1Hw7kxgsbUns5daYFx2M1+JPYsnvF/Bofz+42Btn4TgiIjIfdjZWOPPhaMle2xgcHBwM9v/+979j27Zt+Pzzz9G1a1fY2dnh0UcfRWVlZaPnuX2pDEEQoNVqjVLjnTAISeCR/n744Y/LOJtVhK92peKdCSFSl0RERG1MEIQmX56Smlwub9KSFvv27cP06dP1a3sWFxfjypUrrVzd3TGZeYQsiZVMwFvjewIAViZewZWchtdWIyIiklpgYCAOHTqEK1euICcnp8Hemq5du2LdunVITk7GiRMn8MQTT7RZz05LMQhJZFg3D9zb3QNVGhELtp2VuhwiIqIGzZs3D1ZWVggJCYGHh0eDY36+/PJLdOjQAVFRUZg4cSJGjx6Nfv36tXG1zWNSi66airZadPVcVhHGLt4LrQjE/zUS/QMaXmONiIjMGxddNY52veiqpQn2dsLkAbq5GD7enMJJFomIiNoYg5DE5o7qDnu5FSdZJCIikgCDkMRqJlkEgM9+O4sK9Z1H5RMREZFxMAiZgBn3BMHTSaGfZJGIiIjaBoOQCaiZZBEAlvx+AQWljU88RURERMbBIGQiHunvhx7eTlCVq/HVrlSpyyEiIrIIDEImgpMsEhERtT0GIRPCSRaJiIjaFoOQiXlzXE/IBGDLqSwcu5ondTlERETtGoOQieEki0RERG2HQcgEcZJFIiIyJffddx/mzJljtPNNnz4dkyZNMtr57gaDkAniJItERERtg0HIRHGSRSIiMgXTp09HQkICFi9eDEEQIAgCrly5gjNnzmDcuHFwdHSEl5cXpkyZgpycHP3z/vvf/6J3796ws7ODm5sbRo4ciZKSErz//vv417/+hY0bN+rPt2fPHsneH4OQieIki0RE7ZwoApUl0mzNGH+6ePFiREZGYsaMGcjMzERmZiZsbGxw7733om/fvjh69Ch+++033LhxA5MnTwYAZGZm4vHHH8czzzyDlJQU7NmzBw8//DBEUcS8efMwefJkjBkzRn++qKio1vqU78haslemO3qkvx9++OMyzmYV4atdqXhnQojUJRERkbFUlQKf+Erz2m9eB+QOTWqqVCohl8thb28Pb29vAMC7776Lfv364ZNPPtG3++GHH+Dv74/z58+juLgYarUaDz/8MAICAgAAvXv31re1s7NDRUWF/nxSYo+QCeMki0REZIqOHTuG3bt3w9HRUb/16NEDAHDx4kWEhYVhxIgR6N27Nx577DH885//RH5+vsRV1489QiauZpLFhPM3sWDbWSx7sr/UJRERkTHY2Ot6ZqR67bug1WoxceJEfPbZZ3Ue8/HxgZWVFXbs2IEDBw5g+/bt+Oqrr/DWW2/h0KFDCAoKuqvXNjYGITPw5rie2Hfhpn6Sxf4BrlKXREREd0sQmnx5SmpyuRwaza07mPv164f4+HgEBgbC2rr+KCEIAoYMGYIhQ4bg3XffRUBAANavX4+5c+fWOZ+UeGnMDHCSRSIiklJgYCAOHTqEK1euICcnBy+++CLy8vLw+OOP4/Dhw7h06RK2b9+OZ555BhqNBocOHcInn3yCo0ePIi0tDevWrcPNmzfRs2dP/flOnjyJc+fOIScnB1VVVZK9NwYhM1F7ksXfU7KlLoeIiCzIvHnzYGVlhZCQEHh4eKCyshJ//PEHNBoNRo8ejV69emH27NlQKpWQyWRwdnbG3r17MW7cOHTv3h1vv/02Fi5ciLFjxwIAZsyYgeDgYAwYMAAeHh74448/JHtvgsjuhTpUKhWUSiUKCwvh7OwsdTl6H/zvNH784wpiBvjjs0f7SF0OERE1Q3l5OS5fvoygoCDY2tpKXY7ZauxzbMnfb/YImZF7u3sAAPan5vDyGBERkREwCJmRQUGukFvJkFFQhsu8lZ6IiOiuMQiZEXu5NfoFuADQ9QoRERHR3WEQMjPDulVfHrvAIERERHS3GITMzNCu7gCAxIu5UGu0EldDRETNxTGed8fYnx+DkJnp1VEJpZ0NiirUOHGtUOpyiIioiWxsbAAApaWlEldi3iordYuQW1lZGeV8nFnazFjJBER1ccPWP7Ow/0IO+gd0kLokIiJqAisrK7i4uCA7WzcXnL29PQRBkLgq86LVanHz5k3Y29s3OKN1czEImaGh3dx1QSj1JmaP7CZ1OURE1EQ1q63XhCFqPplMhk6dOhktRDIImaFhXXUDppPSClBcoYajgv8zEhGZA0EQ4OPjA09PT0mXlTBncrkcMpnxRvbwL6gZ6uRmj06u9kjLK8WhS7kY0dNL6pKIiKgZrKysjDbGhe4OB0ubqaHddHeP7eNt9ERERC0maRDau3cvJk6cCF9fXwiCgA0bNjTafvr06RAEoc4WGhqqbxMXF1dvm/Ly8lZ+N22r5jZ6TqxIRETUcpIGoZKSEoSFhWHp0qVNar948WJkZmbqt/T0dLi6uuKxxx4zaOfs7GzQLjMzs90tcBfVxQ2CAKRmFyOzsEzqcoiIiMySpGOExo4di7Fjxza5vVKphFKp1O9v2LAB+fn5ePrppw3aCYKgH5nfXrnYy9GnoxInrhXij9RcPNrfT+qSiIiIzI5ZjxFasWIFRo4ciYCAAIPjxcXFCAgIgJ+fHyZMmICkpKRGz1NRUQGVSmWwmYOacUL7L9yUuBIiIiLzZLZBKDMzE1u3bsVzzz1ncLxHjx6Ii4vDpk2bsGrVKtja2mLIkCG4cOFCg+eKjY3V9zYplUr4+/u3dvlGMbT6Nvr9qbmcsp2IiKgFzDYIxcXFwcXFBZMmTTI4HhERgaeeegphYWEYNmwY1q5di+7du+Orr75q8Fzz589HYWGhfktPT2/l6o2jX4AL7GyskFNcgbNZRVKXQ0REZHbMMgiJoogffvgBU6ZMgVwub7StTCbDwIEDG+0RUigUcHZ2NtjMgcLaCoOCXAEAf/DuMSIiomYzyyCUkJCA1NRUPPvss3dsK4oikpOT4ePj0waVtb1hnE+IiIioxSS9a6y4uBipqan6/cuXLyM5ORmurq7o1KkT5s+fj4yMDKxcudLgeStWrMDgwYPRq1evOuf84IMPEBERgW7dukGlUmHJkiVITk7G119/3ervRwo1A6YPXc5FhVoDhTVnKiUiImoqSYPQ0aNHMXz4cP3+3LlzAQDTpk1DXFwcMjMzkZaWZvCcwsJCxMfHY/HixfWes6CgADNnzkRWVhaUSiXCw8Oxd+9eDBo0qPXeiISCvZzg7qhATnEFjl3NR1QXd6lLIiIiMhuCyNuN6lCpVFAqlSgsLDSL8UJzVidhQ/J1vHBfF7w2pofU5RAREUmiJX+/zXKMEBka2k13Gz0HTBMRETUPg1A7ULPu2MmMQhSUVkpcDRERkflgEGoHvJW26ObpCFEEDlzMlbocIiIis8Eg1E4M5W30REREzcYg1E7UXB7bn8p1x4iIiJqKQaidGNzZDdYyAel5ZUjLLZW6HCIiIrPAINROOCqs0a9TBwDAPvYKERERNQmDUDtSM05oP8cJERERNQmDUDtSE4QOXMyFRst5MomIiO6EQagd6dNRCSdbaxSWVeFURqHU5RAREZk8BqF2xNpKhsjObgA4yzQREVFTMAi1M8P08wlxwDQREdGdMAi1MzXrjh27mo/SSrXE1RAREZk2BqF2JtDNHh1d7FClEXHocp7U5RAREZk0BqF2RhAE/SzTf/A2eiIiokYxCLVD+vmEOGCaiIioUQxC7dCQru4QBOBsVhGyi8qlLoeIiMhkMQi1Q64OcoT6OgPgbfRERESNYRBqp4Z21d09to/jhIiIiBrEINRO6QdMp+ZAFLncBhERUX0YhNqpAYEdoLCW4YaqAqnZxVKXQ0REZJIYhNopWxsrDApyBcDLY0RERA1hEGrHai6P8TZ6IiKi+jEItWM18wkdvJSLSrVW4mqIiIhMD4NQO9bT2xluDnKUVmqQnF4gdTlEREQmh0GoHZPJBETVXB7javRERER1MAi1c8Oqg9A+jhMiIiKqg0GonasZJ3QivQCFZVUSV0NERGRaGITaOV8XO3T2cIBWBBIv5kpdDhERkUlhELIAtWeZJiIiolsYhCwA5xMiIiKqH4OQBYjo4gYrmYDLOSW4ll8qdTlEREQmg0HIAjjb2qCvvwsAYD+X2yAiItJjELIQvDxGRERUF4OQhai5jf7AxVyIoihxNURERKaBQchChPm5QG4lQ15JJdLzyqQuh4iIyCQwCFkIubUMPX2cAAAnrhVIWwwREZGJkDQI7d27FxMnToSvry8EQcCGDRsabb9nzx4IglBnO3v2rEG7+Ph4hISEQKFQICQkBOvXr2/Fd2E+evspAQCnMgolroSIiMg0SBqESkpKEBYWhqVLlzbreefOnUNmZqZ+69atm/6xxMRExMTEYMqUKThx4gSmTJmCyZMn49ChQ8Yu3+z08XMBoFtug4iIiABrKV987NixGDt2bLOf5+npCRcXl3ofW7RoEUaNGoX58+cDAObPn4+EhAQsWrQIq1atuptyzV5YdRD6M6MQWq0ImUyQtiAiIiKJmeUYofDwcPj4+GDEiBHYvXu3wWOJiYmIjo42ODZ69GgcOHCgwfNVVFRApVIZbO1RFw8H2NlYoaRSg0s5xVKXQ0REJDmzCkI+Pj747rvvEB8fj3Xr1iE4OBgjRozA3r179W2ysrLg5eVl8DwvLy9kZWU1eN7Y2FgolUr95u/v32rvQUrWVjL06ugMADiRznFCREREkl4aa67g4GAEBwfr9yMjI5Geno7PP/8c99xzj/64IBhe8hFFsc6x2ubPn4+5c+fq91UqVbsNQ707uuDIlXycyijEI/39pC6HiIhIUmbVI1SfiIgIXLhwQb/v7e1dp/cnOzu7Ti9RbQqFAs7OzgZbexXmr7tzjLfQExERtYMglJSUBB8fH/1+ZGQkduzYYdBm+/btiIqKauvSTFLNnWNnrqtQpdFKWwwREZHEJL00VlxcjNTUVP3+5cuXkZycDFdXV3Tq1Anz589HRkYGVq5cCUB3R1hgYCBCQ0NRWVmJn376CfHx8YiPj9efY/bs2bjnnnvw2Wef4cEHH8TGjRuxc+dO7N+/v83fnykKcLWHk601isrVOH+jCKG+SqlLIiIikoykQejo0aMYPny4fr9mnM60adMQFxeHzMxMpKWl6R+vrKzEvHnzkJGRATs7O4SGhmLz5s0YN26cvk1UVBRWr16Nt99+G++88w66dOmCNWvWYPDgwW33xkyYTCagj58Sf6Tm4tS1QgYhIiKyaILIFTjrUKlUUCqVKCwsbJfjhT7dehbfJFzE44M6Ifbh3lKXQ0REZBQt+ftt9mOEqPnCqpfaOMkB00REZOEYhCxQzZpj57KKUF6lkbgaIiIi6TAIWaCOLnZwc5BDrRWRktk+Z9EmIiJqCgYhCyQIugHTAFeiJyIiy8YgZKF661eiZxAiIiLLxSBkoThgmoiIiEHIYtUMmE69WYySCrXE1RAREUmDQchCeTrZwkdpC1EE/uQ4ISIislAMQhasd0cOmCYiIsvGIGTBwvxdAAAnrjEIERGRZWIQsmD6W+g5YJqIiCwUg5AFq7k0diW3FIWlVRJXQ0RE1PYYhCyYi70cAW72AICTGQXSFkNERCQBBiELV9MrdJLjhIiIyAIxCFm4sOoZpjmxIhERWSIGIQt3a8A0e4SIiMjyMAhZuNCOSggCcL2wHDeLKqQuh4iIqE0xCFk4R4U1uno4AgBOccA0ERFZGAYh0q87xpXoiYjI0jAIEQdMExGRxWIQIn2P0KmMQoiiKHE1REREbYdBiBDi4wxrmYCc4kpcLyyXuhwiIqI2wyBEsLWxQrC3EwCuO0ZERJaFQYgA3JpPiCvRExGRJWEQIgBAn+oB05xYkYiILAmDEAGoveZYAQdMExGRxWAQIgBAsLcT5NYyqMrVuJJbKnU5REREbYJBiAAANlYyhPg4A+B8QkREZDkYhEgvzK/m8hjHCRERkWVgECI9DpgmIiJLwyBEejW30P95vRAaLQdMExFR+8cgRHqdPRzhILdCaaUGqdnFUpdDRETU6hiESM9KJiC01m30RERE7R2DEBnggGkiIrIkDEJkoGbA9MkMBiEiImr/GITIQM2A6ZTrKlSqtRJXQ0RE1LokDUJ79+7FxIkT4evrC0EQsGHDhkbbr1u3DqNGjYKHhwecnZ0RGRmJbdu2GbSJi4uDIAh1tvLy8lZ8J+1HJ1d7KO1sUKnR4vyNIqnLISIialWSBqGSkhKEhYVh6dKlTWq/d+9ejBo1Clu2bMGxY8cwfPhwTJw4EUlJSQbtnJ2dkZmZabDZ2tq2xltodwRBqLUSfYG0xRAREbUyaylffOzYsRg7dmyT2y9atMhg/5NPPsHGjRvxv//9D+Hh4frjgiDA29vbWGVanD5+Suy7kIOT6YV4crDU1RAREbUesx4jpNVqUVRUBFdXV4PjxcXFCAgIgJ+fHyZMmFCnx4ga17ujCwAOmCYiovbPrIPQwoULUVJSgsmTJ+uP9ejRA3Fxcdi0aRNWrVoFW1tbDBkyBBcuXGjwPBUVFVCpVAabJQvz110aO3+jCGWVGomrISIiaj1mG4RWrVqF999/H2vWrIGnp6f+eEREBJ566imEhYVh2LBhWLt2Lbp3746vvvqqwXPFxsZCqVTqN39//7Z4CybL29kWHk4KaLQizmRadigkIqL2zSyD0Jo1a/Dss89i7dq1GDlyZKNtZTIZBg4c2GiP0Pz581FYWKjf0tPTjV2yWREEAX04wzQREVkAswtCq1atwvTp0/Hzzz9j/Pjxd2wviiKSk5Ph4+PTYBuFQgFnZ2eDzdJxJXoiIrIEkt41VlxcjNTUVP3+5cuXkZycDFdXV3Tq1Anz589HRkYGVq5cCUAXgqZOnYrFixcjIiICWVlZAAA7OzsolboejA8++AARERHo1q0bVCoVlixZguTkZHz99ddt/wbNGG+hJyIiSyBpj9DRo0cRHh6uv/V97ty5CA8Px7vvvgsAyMzMRFpamr79t99+C7VajRdffBE+Pj76bfbs2fo2BQUFmDlzJnr27Ino6GhkZGRg7969GDRoUNu+OTPXuzoIXcopQVF5lcTVEBERtQ5BFEVR6iJMjUqlglKpRGFhoUVfJhvy6S5kFJRh1YwIRHZxk7ocIiKiRrXk77fZjRGittPHjwOmiYiofWMQogZxJXoiImrvGISoQcbqEcorqcTfViVh7tpkaLW8EktERKZD0rvGyLT1qp5LKD2vDPkllejgIG/2Of7MKMTz/z6GjIIyAMDUyED09XcxZplEREQtxh4hapDSzgZB7g4AWnZ5LP7YNTyy/IA+BAHAttNZRquPiIjobjEIUaP0l8fSC5r8nEq1Fu9u/BOv/nICFWot7u/hiY8n9QIAbPszC7xRkYiITAWDEDWquQOms1XleOKfB7Ey8SoAYPaIbvh+6gA82NcXcisZLuWUIDW7uLXKJSIiahYGIWpUcwZMH72Sh/Ff7cfRq/lwsrXGimkD8Mqo7pDJBDjZ2iCqq24uIl4eIyIiU8EgRI0K9XWGTABuqCpwQ1VebxtRFLEy8Qr+8t1B3CyqQHcvR2x6aShG9PQyaDcm1BsAsO30jVavm4iIqCkYhKhR9nJrdPN0AgCcrGcB1vIqDeb9chLvbjwNtVbE+D4+WP/CEP0g69pGhnhBJgCnMgpxLb+01WsnIiK6EwYhuqOGLo+l55XikeUHEH/8GmQC8Na4nlj6eDgcFPXPyuDuqMCAAFcAwHb2ChERkQlgEKI7uhWEbvUI7btwEw8s3Y/T11VwdZDjp2cHY8Y9nSEIQqPnig7VXS7jOCEiIjIFLQpC//rXv7B582b9/muvvQYXFxdERUXh6tWrRiuOTIP+zrFrBdBqRSzfcxHTfjiM/NIq9PFT4n9/G4qoru5NOtfo6nFCR67kIbe4orVKJiIiapIWBaFPPvkEdnZ2AIDExEQsXboUCxYsgLu7O1555RWjFkjS6+HjBBsrAfmlVZj6w2F89ttZaEVg8gA/rH0+Eh1d7Jp8Ln9Xe4T6OkMrAjtTeHmMiIik1aIglJ6ejq5duwIANmzYgEcffRQzZ85EbGws9u3bZ9QCSXoKayv08HYGAOxPzYGNlYBPHuqNzx7pA1sbq2afbzTvHiMiIhPRoiDk6OiI3NxcAMD27dsxcuRIAICtrS3KysoaeyqZqf4BHQAAXs4KrHk+Ek8M7nTH8UANqQlC+y/koLhCbbQaiYiImqtFi66OGjUKzz33HMLDw3H+/HmMHz8eAHD69GkEBgYasz4yES/d3xWBbvYY38cXHk6KuzpXdy9HBLk74HJOCfacy8aEPr5GqpKIiKh5WtQj9PXXXyMyMhI3b95EfHw83Nx0MwYfO3YMjz/+uFELJNPg7qjA9CFBdx2CAEAQBP3dY7/9ybvHiIhIOoLIFTDrUKlUUCqVKCwshLOzs9TltEvH0/Lx8LIDcFRY49g7I6Gwbv5YIyIiotpa8ve7RT1Cv/32G/bv36/f//rrr9G3b1888cQTyM/Pb8kpycL09XOBp5MCxRVqHEjNlbocIiKyUC0KQn//+9+hUqkAAKdOncKrr76KcePG4dKlS5g7d65RC6T2SSYTat09xstjREQkjRYFocuXLyMkJAQAEB8fjwkTJuCTTz7BsmXLsHXrVqMWSO1XTRDaceYGNFpeoSUiorbXoiAkl8tRWqpbNHPnzp2Ijo4GALi6uup7iojuZHBnVyjtbJBbUomjV/KkLoeIiCxQi4LQ0KFDMXfuXHz00Uc4fPiw/vb58+fPw8/Pz6gFUvtlYyXDiB6eADi5IhERSaNFQWjp0qWwtrbGf//7XyxfvhwdO3YEAGzduhVjxowxaoHUvo3udWucEG9gJCKitsbb5+vB2+fbTlmlBuEfbUd5lRa//m0oenVUSl0SERGZqZb8/W7RzNIAoNFosGHDBqSkpEAQBPTs2RMPPvggrKw4Hww1nZ3cCvd298C20zew7XQWgxAREbWpFgWh1NRUjBs3DhkZGQgODoYoijh//jz8/f2xefNmdOnSxdh1Ujs2OtRbH4RejQ6WuhwiIrIgLRoj9PLLL6NLly5IT0/H8ePHkZSUhLS0NAQFBeHll182do3Uzo3o4QVrmYDzN4px6Wax1OUQEZEFaVEQSkhIwIIFC+Dq6qo/5ubmhk8//RQJCQlGK44sg9LeBpFddOvV8e4xIiJqSy0KQgqFAkVFRXWOFxcXQy6X33VRZHmiOcs0ERFJoEVBaMKECZg5cyYOHToEURQhiiIOHjyIWbNm4YEHHjB2jWQBokN0q9Enpxcgq7Bc4mqIiMhStCgILVmyBF26dEFkZCRsbW1ha2uLqKgodO3aFYsWLTJyiWQJvJxt0a+TCwBgxxn2ChERUdto0V1jLi4u2LhxI1JTU5GSkgJRFBESEoKuXbsauz6yIKNDvXE8rQC/nc7ClMhAqcshIiIL0OQgdKdV5ffs2aP//YsvvmhxQWS5Rod6I3brWRy8lIeC0kq42HO8GRERta4mB6GkpKQmtRMEocXFkGULdHdAsJcTzt0owu8p2XikP9etIyKi1tXkILR79+7WrIMIgG7tsXM3irDtdBaDEBERtboWDZY2lr1792LixInw9fWFIAjYsGHDHZ+TkJCA/v37w9bWFp07d8Y333xTp018fDxCQkKgUCgQEhKC9evXt0L11BpGh+ruHks4fxOllWqJqyEiovZO0iBUUlKCsLAwLF26tEntL1++jHHjxmHYsGFISkrCm2++iZdffhnx8fH6NomJiYiJicGUKVNw4sQJTJkyBZMnT8ahQ4da622QEYX4OMOvgx0q1FrsPX9T6nKIiKidM5nV5wVBwPr16zFp0qQG27z++uvYtGkTUlJS9MdmzZqFEydOIDExEQAQExMDlUqFrVu36tuMGTMGHTp0wKpVq5pUC1efl9ZHv57Biv2X8VB4R3wZ01fqcoiIyEy05O+3pD1CzZWYmIjo6GiDY6NHj8bRo0dRVVXVaJsDBw40eN6KigqoVCqDjaQzppdulunfU26gUq2VuBoiImrPzCoIZWVlwcvLy+CYl5cX1Go1cnJyGm2TldXwJH2xsbFQKpX6zd/f3/jFU5P169QB7o5yqMrVOHgpV+pyiIioHTOrIATUvT2/5spe7eP1tWnstv758+ejsLBQv6WnpxuxYmouK5mAUdVLbnDtMSIiak1mFYS8vb3r9OxkZ2fD2toabm5ujba5vZeoNoVCAWdnZ4ONpFWzCOuOMzeg1ZrEMDYiImqHzCoIRUZGYseOHQbHtm/fjgEDBsDGxqbRNlFRUW1WJ929qC5ucFJYI7uoAknpBVKXQ0RE7ZSkQai4uBjJyclITk4GoLs9Pjk5GWlpaQB0l6ymTp2qbz9r1ixcvXoVc+fORUpKCn744QesWLEC8+bN07eZPXs2tm/fjs8++wxnz57FZ599hp07d2LOnDlt+dboLimsrTC8hycAXh4jIqLWI2kQOnr0KMLDwxEeHg5At55ZeHg43n33XQBAZmamPhQBQFBQELZs2YI9e/agb9+++Oijj7BkyRI88sgj+jZRUVFYvXo1fvzxR/Tp0wdxcXFYs2YNBg8e3LZvju7a6OrLY9tOZ8FEZnkgIqJ2xmTmETIlnEfINJRUqBH+0Q5UqrX4bc4w9PDm/xZERNSwdj+PEFkWB4U1hnV1BwBs+/OGxNUQEVF7xCBEJm109eSKv3GcEBERtQIGITJpI3t6QSYAKZkqpOeVSl0OERG1MwxCZNJcHeQYFOQKAPjtT/YKERGRcTEIkckb28sHAPDryesSV0JERO0NgxCZvPF9fGAlE3DiWiEu3iyWuhwiImpHGITI5Lk7KnBPN93dYxuTMiSuhoiI2hMGITILk8I7AgDWJ2dwckUiIjIaBiEyC9Eh3nCQWyE9rwzH0/KlLoeIiNoJBiEyC3ZyK/2SG+t5eYyIiIyEQYjMRs3lsV9PZqJSrZW4GiIiag8YhMhsRHVxg4eTAgWlVUg4f1PqcoiIqB1gECKzYW0lwwNhvgCADbw8RkRERsAgRGbloerLYztSbkBVXiVxNUREZO4YhMishPo6o6unIyrVWvx2iktuEBHR3WEQIrMiCIK+V4h3jxER0d1iECKzUzNO6ODlXGQWlklcDRERmTMGITI7/q72GBToClEENiVzIVYiImo5BiEyS5N4eYyIiIyAQYjM0vjePpBbyXA2qwgpmSqpyyEiIjPFIERmSWlvg+E9PAAAG5LZK0RERC3DIERmq+busY1J16HVckV6IiJqPgYhMlv3BXvC2dYaWapyHLycK3U5RERkhhiEyGzZ2lhhfB8fAFxyg4iIWoZBiMzapL66y2NbT2WhvEojcTVERGRuGITIrA0MdEVHFzsUVajxe0q21OUQEZGZYRAisyaTCXiwr26mac4pREREzcUgRGavZnLFPeeykVdSKXE1RERkThiEyOx193JCiI8z1FoRm09lSl0OERGZEQYhahdq5hTi3WNERNQcDELULjzQ1xeCABy7mo+03FKpyyEiIjPBIETtgpezLYZ0cQfAJTeIiKjpGISo3ZhU6/KYKHLJDSIiujMGIWo3Rod6wdZGhks5JTiVUSh1OUREZAYYhKjdcLK1wagQbwCcU4iIiJqGQYjalYfCdZMr/u/Edag1WomrISIiU8cgRO3KsG4ecHWQI6e4EvtTc6Quh4iITJzkQWjZsmUICgqCra0t+vfvj3379jXYdvr06RAEoc4WGhqqbxMXF1dvm/Ly8rZ4OyQxGysZJnJFeiIiaiJJg9CaNWswZ84cvPXWW0hKSsKwYcMwduxYpKWl1dt+8eLFyMzM1G/p6elwdXXFY489ZtDO2dnZoF1mZiZsbW3b4i2RCai5e2zb6RsoqVBLXA0REZkySYPQF198gWeffRbPPfccevbsiUWLFsHf3x/Lly+vt71SqYS3t7d+O3r0KPLz8/H0008btBMEwaCdt7d3W7wdMhF9/V0Q6GaPsioNtp/JkrocIiIyYZIFocrKShw7dgzR0dEGx6Ojo3HgwIEmnWPFihUYOXIkAgICDI4XFxcjICAAfn5+mDBhApKSkho9T0VFBVQqlcFG5ksQBH2v0Pqk6xJXQ0REpkyyIJSTkwONRgMvLy+D415eXsjKuvO/4jMzM7F161Y899xzBsd79OiBuLg4bNq0CatWrYKtrS2GDBmCCxcuNHiu2NhYKJVK/ebv79+yN0UmY1JfXRDaf+Emsos4PoyIiOon+WBpQRAM9kVRrHOsPnFxcXBxccGkSZMMjkdEROCpp55CWFgYhg0bhrVr16J79+746quvGjzX/PnzUVhYqN/S09Nb9F7IdAS6OyC8kwu0IvC/E1yRnoiI6idZEHJ3d4eVlVWd3p/s7Ow6vUS3E0URP/zwA6ZMmQK5XN5oW5lMhoEDBzbaI6RQKODs7GywkfnjivRERHQnkgUhuVyO/v37Y8eOHQbHd+zYgaioqEafm5CQgNTUVDz77LN3fB1RFJGcnAwfH5+7qpfMz/jePrCWCTiVUYjU7CKpyyEiIhMk6aWxuXPn4vvvv8cPP/yAlJQUvPLKK0hLS8OsWbMA6C5ZTZ06tc7zVqxYgcGDB6NXr151Hvvggw+wbds2XLp0CcnJyXj22WeRnJysPydZDjdHBe7p7gEA2MBB00REVA9rKV88JiYGubm5+PDDD5GZmYlevXphy5Yt+rvAMjMz68wpVFhYiPj4eCxevLjecxYUFGDmzJnIysqCUqlEeHg49u7di0GDBrX6+yHTMym8I3adzcb6pAzMuKczlHY2UpdEREQmRBBFUZS6CFOjUqmgVCpRWFjI8UJmrqxSg0Gf7ERRuRrOttZ4/t4umB4VCAeFpP8GICKiVtCSv9+S3zVG1Jrs5Fb4fuoAdPdyhKpcjf/bdg73/t9urNh/GeVVGqnLIyIiibFHqB7sEWp/NFoR/ztxHV/uPI+ruaUAAG9nW/xtRFdMHuAPGyv+m4CIyNy15O83g1A9GITaryqNFvHHrmHJ7xdwvVA30WInV3vMGdkND/btCCvZneewIiIi08QgZCQMQu1fhVqDnw+l4evdF5FTXAEA6OrpiLmjumNMqDdkDERERGaHQchIGIQsR2mlGv86cBXfJFxEYVkVACDU1xnzooNxX7BHk2Y5JyIi08AgZCQMQpZHVV6F7/ddxop9l1BSqRtE3T+gA16N7o6oLu4NPq+8SoP80krkl1ShoLQS+aVV1fu63wtKK1Gu1sBebg0HuRUcFNa6rfbvtfYdFdawr/5dYS1jECMiagYGISNhELJceSWV+DbhIv6VeAXlVVoAQFQXN3T2cNAHm5rQk1daqW/TGqxkAhzkVvB0tkVHFzv4dbCDXwd7dOxQ/buLHdwdFbyMR0RUjUHISBiEKFtVjqW7U7HqcBqqNI3/J2IlE9DB3gYu9nJ0sLdBB3s5OtjL4eKg+93OxgollWqUVmhQXKFGaaUaJbV+L67QVB/THS9rxm39cmtZrZBkV/37rbDk6WTLAeBEZDEYhIyEQYhqXMsvxdqj1wBR1AUdh5rAI4drddhxUlgb9RKWRivWCk5VyCqsQEZBKa7llyEjvwzX8stwLb8UWapyaO/wX6+D3AoxAzvh2WFB6OhiZ7QaiYhMEYOQkTAIkTmo0miRVViuD0YZBWW3wlJBKTILyqGuTkpWMgEPhPli5j2d0dOH32kiap8YhIyEQYjaA41WxP7UHHybcBEHLubqj9/b3QPP39sZkZ3dOBibiNoVBiEjYRCi9ubktQJ8u/cStp7K1F9OC/NT4vl7u2B0qDfHERFRu8AgZCQMQtReXc0twff7LmPt0XRUqHV3vAW42WPGsM54tL8fbG2sJK6QiKjlGISMhEGI2rvc4gr8K/EqViZeQUGpbiJJNwc5pkcFYkpkAFzs5RJXSETUfAxCRsIgRJaitFKNtUfS8c99l5FRUAYAsJdb4S+804yIzBCDkJEwCJGlUWu02HwqE98kXEJKpgqA7k6ziM6uCPFxRs/qrYuHI+TWMomrJSKqH4OQkTAIkaUSRRH7LuTg270X8Udqbp3HbawEdPV0Qk9vJ3046unjBDdHhQTVEhEZYhAyEgYhIuD8jSIcv5qPlEwVUrKKkJKpQlG5ut62nk4K9KgORTU9SJ3dHWBtxd4jImo7DEJGwiBEVJcoisgoKENKpi4Unc1SISWzCFdyS1Df/4vYy63w3LDOeOG+LrwbjYjaBIOQkTAIETVdSYUa525UhyN9SCpCcYWu98jf1Q7vTwzFiJ5eEldKRO0dg5CRMAgR3R2tVsTWP7Pw8eYzyCwsBwCM7OmJ9yaGwt/VXuLqiKi9asnfb17AJyKjk8kEjO/jg51z78Wse7vAWiZgZ0o2Rn6RgMU7L6C8SiN1iUREABiEiKgVOSis8cbYHvhtzjBEdXFDhVqLL3eeR/SXe7H7bLbU5RERMQgRUevr6umE/zw3GF89Hg4vZwXS8krxdNwRzFh5FOl5pVKXR0QWjEGIiNqEIAiYGOaL31+9DzPv6QxrmYAdZ25g1JcJWLrrAirU7eNymVbLYZdE5oRBiIjalKPCGm+O64kts4chorMryqu0+Hz7eYz+ci/2nDPvy2W7z2Yj+J2t+GL7OalLIaImYhAiIkl093LCqhkRWPyXvvB0UuBKbimm/3gEs/59TL/umTkpr9LgnY1/okojYsmuVPz2Z5bUJRFREzAIEZFkBEHAg3074vdX78WzQ4NgJRPw2+ksjFi4B3F/XJa6vGb58Y8ruJZfBpmg2//7LydwJadE2qKI6I4YhIhIck62NnhnQgg2vzwUgwJ1l8ve/98ZbD6ZKXVpTXKzqAJf704FAHz6cB8MCOiAogo1/vqf45wqgMjEMQgRkcno4e2MNc9HYMawIADA6/EncelmscRV3dkXO86huEKNPn5KPNrfD0uf6Ad3RzlSMlV4d+OfUpdHRI1gECIikyIIAl4f0wODglxRXKHGC/85jrJK0+1VSclUYc2RdADAOxNCIJMJ8FbaYvFfwiETgLVHr2Ft9eNEZHoYhIjI5FhbybD08XC4OypwNqsIb2/4E6a4GpAoivh48xloRWB8bx8MDHTVPzakqzvmjuoOAHhn4584c10lVZlE1AgGISIySZ7OtljyeF/IBCD++DWsPWp6vSq/p2Tjj9RcyK1keGNsjzqPv3BfVwwP9kCFWosX/nMMqvIqCaokosYwCBGRyYrq4o5Xo4MBAO9uPI3T1wslruiWSrUWn2xJAQA8Oyyo3sVkZTIBX8b0RUcXO1zJLcXffzlhkj1bRJaMQYiITNpf7+1Sq1fluMn0qvz74FVcyimBu6McL9zXpcF2LvZyLHuyH+RWMmw7fQMr9pvXtABE7R2DEBGZtNq9KldNpFclv6QSi3eeBwC8Gh0MJ1ubRtuH+bvgnYkhAIDYrWdx5Epeq9dIRE0jeRBatmwZgoKCYGtri/79+2Pfvn0Ntt2zZw8EQaiznT171qBdfHw8QkJCoFAoEBISgvXr17f22yCiVlTTq2JjJZhEr8ri3y9AVa5GD28nTB7g36TnPDW4Ex7s6wuNVsSL/zmOm0UVrVwlETWFpEFozZo1mDNnDt566y0kJSVh2LBhGDt2LNLS0hp93rlz55CZmanfunXrpn8sMTERMTExmDJlCk6cOIEpU6Zg8uTJOHToUGu/HSJqRWH+Lnh3gq5X5dOtZ3FUol6V1Owi/PvgVQDAuxNCYFUzlfQdCIKATx7qja6ejsguqsDs1UnQcIFWIskJooR9zIMHD0a/fv2wfPly/bGePXti0qRJiI2NrdN+z549GD58OPLz8+Hi4lLvOWNiYqBSqbB161b9sTFjxqBDhw5YtWpVk+pSqVRQKpUoLCyEs7Nz894UEbUaURTx8upk/O/EdXg72+LXl4fC3VHRpjU8/eNh7D53EyN7euH7aQOa/fzU7CI8sPQPlFZq8NLwrpg3OrgVqiSyTC35+y1Zj1BlZSWOHTuG6Ohog+PR0dE4cOBAo88NDw+Hj48PRowYgd27dxs8lpiYWOeco0ePvuM5icj0CYKA2Id7o4uHA7JU5ZizOrlNe1X2nr+J3eduwlom4M1xdW+Xb4qunk749JE+AIClu1Ox6+wNY5ZIRM0kWRDKycmBRqOBl5eXwXEvLy9kZdW/arOPjw++++47xMfHY926dQgODsaIESOwd+9efZusrKxmnRMAKioqoFKpDDYiMk2OCmssf6o/7GyssD81B4t/v9Amr6vWaPHx5jMAgKmRgejs4djicz0Q5oupkQEAgFfWnMC1/FKj1EhEzSf5YGlBMLy+LopinWM1goODMWPGDPTr1w+RkZFYtmwZxo8fj88//7zF5wSA2NhYKJVK/ebv37TBj0Qkje5eToh9uDcA4KtdF5Bw/marv+bqI+k4f6MYLvY2mD2i252fcAdvje+JMH8XFJZV4YX/HEeF2nSXESFqzyQLQu7u7rCysqrTU5OdnV2nR6cxERERuHDh1r8Ivb29m33O+fPno7CwUL+lp5veDLZEZGhSeEc8MbgTRBGYszoJ1wvKWu21Csuq8MUO3e3yr4zsDqV947fLN4XC2gpfPxEOF3sbnLxWiI9/TbnrcxJR80kWhORyOfr3748dO3YYHN+xYweioqKafJ6kpCT4+Pjo9yMjI+ucc/v27Y2eU6FQwNnZ2WAjItP37oQQ9OrojPzSKrz483FUqrWt8jpf705FXkklung44InBnYx2Xr8O9vgypi8EQTdB48bkDKOduzlEUcT5G0VISsuX5PWJpGQt5YvPnTsXU6ZMwYABAxAZGYnvvvsOaWlpmDVrFgBdT01GRgZWrlwJAFi0aBECAwMRGhqKyspK/PTTT4iPj0d8fLz+nLNnz8Y999yDzz77DA8++CA2btyInTt3Yv/+/ZK8RyJqPbY2Vlj+ZH+MX7IPSWkFiN2agvcmhhr1Na7mluDHP3TzFr09PgQ2Vsb99+PwYE/8bXhXLNmVijfiTyHExxndvJyM+hq302pFnM8uwqFLeTh4KReHLuchr6QSAPDamGC8cF/XVn19IlMiaRCKiYlBbm4uPvzwQ2RmZqJXr17YsmULAgJ0gwgzMzMN5hSqrKzEvHnzkJGRATs7O4SGhmLz5s0YN26cvk1UVBRWr16Nt99+G++88w66dOmCNWvWYPDgwW3+/oio9fm72mPh5L6YsfIofvzjCgYGumJcb587P7GJYrecRZVGxD3dPXBfsIfRzlvb7JHdcSwtH3+k5mLqD4dxX7AHOrs7IsjdAZ09HODvan9XAUyrFXHuRpEu9FzKw6HLucgvNVyqRG4tQ6VaiwW/nYOzrQ2eigi427dFZBYknUfIVHEeISLzE7s1Bd8mXIKjwhqbXhpyV3d11Ui8mIvH/3kQVjIBW2cPQ/dW7KnJKa7AxK/2I7OwvM5j1jIBnVztEeTuUB2OdCGpi4cDPJwUdW4G0WpFnM3SBZ+Dl3Jx+EoeCm4LPnY2VhgQ2AGDg1wR0dkNffxcsOT3C1i6OxWCACyK6YsH+3ZstfdL1Bpa8vebQageDEJE5ket0eKJ7w/h8OU89PB2wpqZkXc1qFmjFfHA0v04fV2FpyI64eNJvY1Ybf0KSiux59xNXLpZjEs5Jbh0swSXc0pQVtXwHWWOCmt9QPLrYIcL2cU4fDkPhWWGwcdeboUBga764NO7oxJya8NeJlEU8d6m01iZeBXWMgHfTumPET2bfvMKkdQYhIyEQYjIPGWryjFuyX7kFFfAWiZgYKArRvT0xIieXghyd2jWudYeTcdr/z0JJ1tr7Jl3H9zaeAbrGqIoIktVjss3S2qFI11QSs8rRUPzSTpUB5+Izm4Y3NkVvTsqm3R5TasV8eovJ7A+KQMKaxninh6EyC5uRn5XRK2DQchIGISIzNexq/l4I/4kLmQXGxzv7O6A+3t44v6enhgY6NpoKCipUOO+z/fgZlEF3hrXEzPu6dzaZbdIpVqLtDxdOKoJRv6u9ojo7IZevs6wbuG4oiqNFn/96Th2ptyAg9wKP8+IQJi/i3GLJ2oFDEJG0mpBSF0BFN8AbJWA3AmQST6fJVG7dSWnBLvOZmPX2WwcupyLKs2t/6tzsrXGvd09MKKnJ+7r7okODnKD5y7cfg5f7UpFgJs9tr9yDxTWVm1dvuTKqzR4+scjSLyUCxd7G6x9PrJVx0gRGQODkJG0WhDKPAF8e4/ud0EGKJx1ocjORffTVgnYutz6We/x6s3GDmhktmwiuqWovAr7LuTg95Rs7D6Xrb9VHABkAtA/oAPu7+GFET09YS+3woiFCahQa/HNU/0xppe3hJVLq7hCjSe/P4QT6QXwdFLgv7Oi0MnNXuqyiBrEIGQkrRaEriYCKx8ENBV3fy6ZtS4QKZwBW+dav7vctl/791pBSuEMWEk6ewKRJDRaESeuFWBXSjZ2ptzA2awig8ftbKxQVqVBRGdXrJoR0ejyPJagoLQSMd8exLkbRejkao9fZkXCy9lW6rKI6sUgZCStPkaoqhwoLwTKC3Q/ywpq7df8fvvxwlubaKTZc+VOhuGoKZudC2DXQRekLPwPBLUPGQVluktoKTfwx8VcVKq1kAnAppeGoldHpdTlmYRsVTke/SYRaXml6O7liDUzI+tcTrwbWq2Iogo1lHZ3v3QJWTYGISMx6cHSoghUFleHIhVQoar1e2H9x8sLDferSu6+DkF26/KdXQfdZlvzu0v9+zWbtTR33xDdSWmlGgcv5UJpZ4P+Aa5Sl2NS0vNK8eg3B3BDVYEwfxf857nBcFTcXa9ybnEF1h69hp8PX0VGfhn+dn83zB7RDTIZ/5FFLcMgZCQmHYSMQVNVHZAKDHua7rgV6Hqp1He5uKWNgy4Q2deEI9fqfddb+7V/rwlQvJRHJKkLN4ow+dtE5JdWIbKzG358eiBsbZo3kFwURRxPy8e/E69iy6ksVGoMe7hH9vTEFzF94WzL3iFqPgYhI2n3QehuVZVXh6J8XTAqy6+1X9+xWvt3c1lPoawOTzVByRWwd7sVmuyr92s/LufATiJjOnmtAE/88xCKK9QY2dMLy5/q16T5iUoq1NiQnIF/J141GJfVx0+JpwYHQISIdzaeRqVai84eDvhuygB09bz72cHJsjAIGQmDUCvRanWX78rygdKa0JRXvZ/X8H55Yctf09quOiDVhKYmbNbGG/tA1B4dvJSLaT8cRoVai0l9ffHF5L4NXs46f6MIPx28inXHM1BcoQYAKKxleCDMF09FBBjMT3TyWgFm/fsYrheWw1FhjYWTwzA61HLv2qPmYxAyEgYhE6PVVPcq5ekCUmnurd8NjuUbHtNW3fHU9VI41x+cHNwBe/daP910PxVOHDhOFmfX2RuYufIY1FoRUyIC8OGDofo77CrVWvx2Ogs/HbyKw5fz9M8JcnfAk4M74dH+fnCxr/8fHDnFFXjxP8dxqPp5L9/fFXNGdue4oXpsTM7AzaIKPDMkiJ9PNQYhI2EQagdqBpWX5lYHpZqAlAuU5FQfz70VokpzdL+LDa/p1CAruWEwuj0oOXjojtX85B131E5sTM7AnDXJEEXgxeFd8MTgAPx86CrWHElHTrFuriYrmYBRPb3wVEQAorq4NekPdpVGi0+2pODHP64AAO7v4YkvY/qa3F1l+SWVWLDtHBTWMrw5rmedtdta0w/7L+PDX88AAOaO6o6XR3Rrs9c2ZQxCRsIgZKFqLt2V3h6Ycm7tl+To9kuqj1eVNv91ZDbVocit+qfHrQClD0we1b1QHoDcgcGJTNZ/Dl3FW+v/BKD7mtb8RfF0UuDxQZ3w+KBO8Fa2bN6hdcevYf66U6hQaxHk7oDvpvRHNxOZ3Xr/hRzMXZuM7CLdvHBjQr3x1RPhTRovdbfij13Dq7+c0O8LAvCvpwfhnu4erf7apo5ByEgYhKjJKkurg1GtsFSaA5TcvBWW9MdydL1UzWVtpwtEjh61epc8bwUmB3fA0fNWeJJZ3nIQJK1vEi7i061nAQBRXdwwJSIAI0O8jBIK/swoxPP/PoaMgjI4yK2wcHIYxvTyuevztlSFWoPPt53DP/ddBgAEutnjekE5KjVaTOjjg0UxfVu8xltT7DhzA7N+OgaNVsSzQ4NQWqnGqsPp6GBvg//9bSj8Olj2DSIMQkbCIEStpqqsumfpZnVwutnAfvWxZk9VINzqSaodkBw8AEevW/s1PzmnExnJ0St5cHWQo7OH8e/0yi2uwEs/JyHxUi4A4KXhXfHKqO6wauNxMRduFOHl1clIyVQBAJ6K6IS3xoXgwMUczPrpGKo0Iib19cXCyX1bpbbEi7mY9uNhVKq1eLS/HxY80geVGi0e+yYRpzIKEeanxNpZkRa5Nl4NBiEjYRAik1FRfKs3qTi7OijdthXfvBWk0Mz/nG2Vut4lg4Dkqet9cvS69ZijJ0MTSUqt0SJ261ms2K/riRke7IFFfwlvk3FDoijip4NX8fHmFFSotXB1kGPBI30wMsRL32bb6Sy8+J/jUGtFfUgx5gDm2tMWRId4YdmT/fQ9T9fySzHhq/0oKK3CE4M74ZOHehvtdc0Ng5CRMAiRWdJqavUq1QSk7FsBqji7er/68ebeVWfrUh2KvGoFppp9r1vhyd6dk19Sq9mQlIE31p1EeZUWgW72+HbKAAR7t964oZziCrz+35P4/Ww2AGBYN3csfCwMnvWst7blVCb+tioJGq2Ixwf54x+TehslDKVmF+Gxb3QTWUZ1ccMP0+tOZJlw/iam/3gYogh8/lgYHu3vd9eva44YhIyEQYjaPVHUTTdgEJCybwtL1T+LbzQzNAm3xjE5eQGO3rrA5OStC0o1Px29AAUnzKPmqz1uyF5uhYWPhWFsb+OPG9pzLhvzfjmJnOIKyK1keGNsD0yPCmw03GxMzsAra5KhFVFnWoGWuJZfise+SURmYTnC/JT4z4yIBpc2WbzzAr7ceR4KaxnWvRCFUF/LWyuPQchIGISIajEITTeqA9ONW8Gp5veS6p6n5sweLne8FYpqQpOTV61j1aHJzhWQtd2tyWT68koq8bdVx/FHqm7c0MPhHTG8hyciOrvBw+nuLuOWV2nw6daziDtwBQDQ3csRi/8Sjp4+Tft7sO647q4uUQSeHhKIdyeEtCgM5RRX4LFvEnE5pwRdPR3xy/ONL3ar1Yp45l9HsOfcTXRytcf/XhoKpb1pTTnQ2hiEjIRBiKiFai7PFWcDxVm6n0VZurBUlHXreNGN5i3+K7NuoIfJs3rf61aA4lgmi6HWaLFg2zl8t/eSwfHuXo6I6uKOyC5uiAhya1YYOJulwuxVyTh3Q7cMyPSoQLwxtkez11RbeyQdr8WfBADMvKcz5o/t0awwpCqvwuPfHcTp6yp0dLHDf/8aCR+l3R2fV1BaiQlf7ce1/DKM6OGJf04dYFGTLTIIGQmDEFEbqCjSBaLiG7fC0e3hqfhG9SDwZrB1MbwM5+Rd3dPkbXhc7tAqb4va3sFLudhx5gYOXMzV39FVQxCAUF9nfTAaGOha76UlURTx4x9X8OlvZ1Gp1sLdUY7/ezQMw3t4triu2nMsvTi8C+ZFBzcpDJVXaTB1xWEcvpIHd0c5fpkVhSD3pn9f/8woxMPLD6BSrcW86O546X7LmWyRQchIGISITIi6svqyXFat4FS93b6vqWz6eRXOjQcmJx/dxoV7zUpeSSUOXcrFgYu5OHAxBxdvGvY8WskEhPkpEdXFHVFd3NAvoANU5VX4+y8nkXD+JgDdTNYLHu0Dd8e7713814EreG/TaQDA7BHd8Mqo7o22r9Jo8fy/j2HX2Ww42Vpj9cyIFo31WXMkDa/Hn4IgACufGYRh3SxjskUGISNhECIyQzVjmfSX4Wr/zLzV41SU1bwZwW2V1aHIG3DyvRWSnH1uHXf0AqwsayyGubihKsfBS7k4kJqLA5dykJ5nODeX3FoGhZUMRRVqKKxleGt8T0yJCLirAc63+37fJXy8OQUAGu2h0WpFvLI2GRuTr8PWRoZ/PzsYAwNdW/y6r//3JNYc1U22+OvLw9DR5c6X1swdg5CRMAgRtWOiqLssV19AqtmKswBVZjPGMQm6eZicvAFnX8MeJX2I8qme+ZuDvqWUnleKxIu5SLyk6zG6odItkdHD2wlLHg9H91ZawqP27Nvzx/bA8/d2MXhcFEW8t+k0ViZehbVMwD+nDcDw4JZflgN0l9ge/eYA/sxQIczfBWufjzCJyRZV5VX4+NczuL+Hp9FnCWcQMhIGISLSB6aiLKDoevXPTF1AKqrZqo9p1U07p8xad/nNuVY4MvhZHaJslVxfrg2IoohLOSXIKizHgMAOrR4Slu66gM+3nwcAvDMhBM8ODdI/9sWO81jy+wUIArD4L+F4IMzXKK+ZnqebbLGwrApPRXTCx5OknWzxj9Qc/P2XE7heWA53RwX2vz682QPRG8MgZCQMQkTUZFqtbkC3PhjVCk1FWYCqer/kJpo887eNffXlN9/qHiYfw5/Ovrq76DhxpdmpCTwA8OGDoZgaGYgV+y/jo+qV5D+a1AtTIgKM+pq7z2XjmbgjEEXgi8lheLhf20+2WFqpxqdbz2Jl4lUAQCdXe3z+WBgGBbX80l99GISMhEGIiIxOU1V9R9xtvUmq2/bLC5p2PkFWPdC7nsDk7As4d+RgbxMkiiL+b9s5LNtzEQDwUHhHrE/KAAD8fXQwXhzetVVe98sd57H49wuwtZFh/QtDmjwnkjEcuZKHeb+cwNVc3di8KREBeGNsDzg0MDHk3WAQMhIGISKSTGVpdUC6ftvPDMPQJGqadj5bl1rhyFd3+c1g3wew68BLcW1IFEXEbj1rMP/RjGFBeHNcT6MO0q5NqxXxdNwRJJy/iQA3e2x6aWirr9NWXqXBwu3n8P3+yxBFwEdpiwWP9mnVO9gYhIyEQYiITJpWU927dP1WOFJdrw5N1cdU15s+2Nvarm44cu6oG8tUE54cPQGZ9ANt2wtRFPHx5hSs2H8Zjw/yxycP9W61EFQjv0Q32WJGQRlG9vTCd1P6t9pkiyfSC/DqLyeQml0MAHisvx/emRgCZ9vWDV8MQkbCIEREZk8UgfJCw94kfVCqCUsZQFle084nWNW6K652UOp465iTD2BTdzFSalheSSVcG1k2w9hOXSvEI9/oJltsjUtxlWotlvx+AcsTLkKjFeHhpMCnD/fGiJ5eRn2dhjAIGQmDEBFZjKqyW2OVDILS9VuX5Yoym76GnL1brctvPrfGKtXucVI481KchFYfTsMb605BJgCzR3THkK5u6O2nvOu75s5cV+HVX07oZ/eeGOaLDx8IbXR9NGNjEDISBiEiolo0at2iujW9SA31MqnLm3Y+G4fGg5JzR8DenXMutaLX/nsCa49e0+/LrWUI81Oif4ArBgZ2QP+ADnCxb1qAUWu0+CbhIhb/fgFVGhEd7G3w8aTeGN/HuHMENQWDkJEwCBERNVPNzN63D+7WB6fq35t6V5zMpnq+pdsCUu3A5OjNKQRaqFKtxZojafgjNRdHr+Yhp7ju8jTdPB0xIFAXjAYEuMLf1a7OOKbU7GK8ujYZJ64VAgBGhXjhk4d6w8NJmsWPGYSMhEGIiKiV1L4rrr5Lcarrulm/mzLnUn1TCOjvjKvV28QpBBoliiKu5JbiyJU8HLuSjyNX83DpZt2B9p5OCgwMdEX/gA4YGOiKQ5dz8X/bzqFCrYWTrTU+eCAUD4V3bPVB341hEDISBiEiIglpqnRhSHW9umfp+m2/Z+oCVFNn9K6ZQqCxwMQpBAzkFlfg2NV8HL2ajyNX8vBnRiGqNPXHhXu6e+CzR3rDRyn9WmYMQkbCIEREZOK0Wt1s3TXhqKHLcU2eQsC2nstvHTluqVp5lQYn0gv0wejY1XzIBAFvjO2Bvwz0l7QXqDazDELLli3D//3f/yEzMxOhoaFYtGgRhg0bVm/bdevWYfny5UhOTkZFRQVCQ0Px/vvvY/To0fo2cXFxePrpp+s8t6ysDLa2Tbutk0GIiKgdMJhCoNZdcLfPuVSa07Tz1Yxbqi8s1YxlcvSyiHFLWq0IQYDJBKAaLfn7Len/WmvWrMGcOXOwbNkyDBkyBN9++y3Gjh2LM2fOoFOnTnXa7927F6NGjcInn3wCFxcX/Pjjj5g4cSIOHTqE8PBwfTtnZ2ecO3fO4LlNDUFERNROCAJg56LbPHs23E5dYRiQ9Jfgal2WK8oCtFVAQZpua/A1ZdUL6942g3ft8OTkA1hLM5jYWFprIkYpSNojNHjwYPTr1w/Lly/XH+vZsycmTZqE2NjYJp0jNDQUMTExePfddwHoeoTmzJmDgoKCFtfFHiEiIjLQ0LilwmuGS6E0ddySg0f9M3jXHuRty78/zWVWPUKVlZU4duwY3njjDYPj0dHROHDgQJPOodVqUVRUBFdXw9Vri4uLERAQAI1Gg759++Kjjz4y6DG6XUVFBSoqKvT7KpWqGe+EiIjaPSsbQOmn2xqi1VSPW7peT+/SbfMtldzUbVknGz6f3LHuIG+D3311gcpCxy0Zi2RBKCcnBxqNBl5ehtNue3l5ISsrq0nnWLhwIUpKSjB58mT9sR49eiAuLg69e/eGSqXC4sWLMWTIEJw4cQLdunWr9zyxsbH44IMPWv5miIiIZNXLkDh5Ax371d9GP99S7ctvmYZjllTXgYpCoLIYyDmv2xp8Tetby5vo512q9bMmPNlIf0eXqZJ8RNftA61EUWzS4KtVq1bh/fffx8aNG+Hp6ak/HhERgYiICP3+kCFD0K9fP3z11VdYsmRJveeaP38+5s6dq99XqVTw9/dv7lshIiJqnCAA9q66zbt3w+0qS267A66ewd7FN3SX4grTdVtj7DrUCkk+hr1LNT/t3SxyCgHJgpC7uzusrKzq9P5kZ2fX6SW63Zo1a/Dss8/il19+wciRIxttK5PJMHDgQFy4cKHBNgqFAgqFeQ9cIyKidkTuALh31W0N0ah1Yai+O+Fqj1uqKtX1QpXlA9mnGz6flby6R+u2XqXagakdLqwrWRCSy+Xo378/duzYgYceekh/fMeOHXjwwQcbfN6qVavwzDPPYNWqVRg/fvwdX0cURSQnJ6N370aSNxERkbmxsgaUHXVbQ2qmEGgoJNX8LLkJaCrvfFccANi51gpG1XfIGQQoH7Oac0nSS2Nz587FlClTMGDAAERGRuK7775DWloaZs2aBUB3ySojIwMrV64EoAtBU6dOxeLFixEREaHvTbKzs4NSqQQAfPDBB4iIiEC3bt2gUqmwZMkSJCcn4+uvv5bmTRIREUml9hQCXiENt1NXAsVZt2btNvhZKzCpy4GyPN1248+Gzyezrp5GwOe2MUy1e5i8AYWTsd9xs0kahGJiYpCbm4sPP/wQmZmZ6NWrF7Zs2YKAgAAAQGZmJtLSbiXTb7/9Fmq1Gi+++CJefPFF/fFp06YhLi4OAFBQUICZM2ciKysLSqUS4eHh2Lt3LwYNGtSm742IiMhsWMsBl066rSE1A71rZu2uHZT0YSlL17ukVQOqa7qtIZ6hwAtNu0u8NUk+s7Qp4jxCRERELaSfc6mekFRU/VOVCfgPAqasM+pLm9U8QkRERNQONWXOJUB3Oc4EmMdIJiIiImpfrOVSVwCAQYiIiIgsGIMQERERWSwGISIiIrJYDEJERERksRiEiIiIyGIxCBEREZHFYhAiIiIii8UgRERERBaLQYiIiIgsFoMQERERWSwGISIiIrJYDEJERERksRiEiIiIyGJZS12AKRJFEQCgUqkkroSIiIiaqubvds3f8aZgEKpHUVERAMDf31/iSoiIiKi5ioqKoFQqm9RWEJsTmyyEVqvF9evX4eTkBEEQjHpulUoFf39/pKenw9nZ2ajnbs/4uTUfP7OW4efWMvzcWoafW/M19pmJooiioiL4+vpCJmva6B/2CNVDJpPBz8+vVV/D2dmZX/oW4OfWfPzMWoafW8vwc2sZfm7N19Bn1tSeoBocLE1EREQWi0GIiIiILBaDUBtTKBR47733oFAopC7FrPBzaz5+Zi3Dz61l+Lm1DD+35jP2Z8bB0kRERGSx2CNEREREFotBiIiIiCwWgxARERFZLAYhIiIislgMQm1o2bJlCAoKgq2tLfr37499+/ZJXZJJe//99yEIgsHm7e0tdVkmZ+/evZg4cSJ8fX0hCAI2bNhg8Lgoinj//ffh6+sLOzs73HfffTh9+rQ0xZqQO31u06dPr/P9i4iIkKZYExEbG4uBAwfCyckJnp6emDRpEs6dO2fQht+3upryufH7Zmj58uXo06ePftLEyMhIbN26Vf+4Mb9nDEJtZM2aNZgzZw7eeustJCUlYdiwYRg7dizS0tKkLs2khYaGIjMzU7+dOnVK6pJMTklJCcLCwrB06dJ6H1+wYAG++OILLF26FEeOHIG3tzdGjRqlX1PPUt3pcwOAMWPGGHz/tmzZ0oYVmp6EhAS8+OKLOHjwIHbs2AG1Wo3o6GiUlJTo2/D7VldTPjeA37fa/Pz88Omnn+Lo0aM4evQo7r//fjz44IP6sGPU75lIbWLQoEHirFmzDI716NFDfOONNySqyPS99957YlhYmNRlmBUA4vr16/X7Wq1W9Pb2Fj/99FP9sfLyclGpVIrffPONBBWapts/N1EUxWnTpokPPvigJPWYi+zsbBGAmJCQIIoiv29NdfvnJor8vjVFhw4dxO+//97o3zP2CLWByspKHDt2DNHR0QbHo6OjceDAAYmqMg8XLlyAr68vgoKC8Je//AWXLl2SuiSzcvnyZWRlZRl89xQKBe69915+95pgz5498PT0RPfu3TFjxgxkZ2dLXZJJKSwsBAC4uroC4PetqW7/3Grw+1Y/jUaD1atXo6SkBJGRkUb/njEItYGcnBxoNBp4eXkZHPfy8kJWVpZEVZm+wYMHY+XKldi2bRv++c9/IisrC1FRUcjNzZW6NLNR8/3id6/5xo4di//85z/YtWsXFi5ciCNHjuD+++9HRUWF1KWZBFEUMXfuXAwdOhS9evUCwO9bU9T3uQH8vtXn1KlTcHR0hEKhwKxZs7B+/XqEhIQY/XvG1efbkCAIBvuiKNY5RreMHTtW/3vv3r0RGRmJLl264F//+hfmzp0rYWXmh9+95ouJidH/3qtXLwwYMAABAQHYvHkzHn74YQkrMw0vvfQSTp48if3799d5jN+3hjX0ufH7VldwcDCSk5NRUFCA+Ph4TJs2DQkJCfrHjfU9Y49QG3B3d4eVlVWdpJqdnV0n0VLDHBwc0Lt3b1y4cEHqUsxGzV12/O7dPR8fHwQEBPD7B+Bvf/sbNm3ahN27d8PPz09/nN+3xjX0udWH3zdALpeja9euGDBgAGJjYxEWFobFixcb/XvGINQG5HI5+vfvjx07dhgc37FjB6KioiSqyvxUVFQgJSUFPj4+UpdiNoKCguDt7W3w3ausrERCQgK/e82Um5uL9PR0i/7+iaKIl156CevWrcOuXbsQFBRk8Di/b/W70+dWH37f6hJFERUVFcb/nhlhIDc1werVq0UbGxtxxYoV4pkzZ8Q5c+aIDg4O4pUrV6QuzWS9+uqr4p49e8RLly6JBw8eFCdMmCA6OTnxM7tNUVGRmJSUJCYlJYkAxC+++EJMSkoSr169KoqiKH766aeiUqkU161bJ546dUp8/PHHRR8fH1GlUklcubQa+9yKiorEV199VTxw4IB4+fJlcffu3WJkZKTYsWNHi/7c/vrXv4pKpVLcs2ePmJmZqd9KS0v1bfh9q+tOnxu/b3XNnz9f3Lt3r3j58mXx5MmT4ptvvinKZDJx+/btoiga93vGINSGvv76azEgIECUy+Viv379DG6dpLpiYmJEHx8f0cbGRvT19RUffvhh8fTp01KXZXJ2794tAqizTZs2TRRF3S3N7733nujt7S0qFArxnnvuEU+dOiVt0Sagsc+ttLRUjI6OFj08PEQbGxuxU6dO4rRp08S0tDSpy5ZUfZ8XAPHHH3/Ut+H3ra47fW78vtX1zDPP6P9eenh4iCNGjNCHIFE07vdMEEVRbEEPFREREZHZ4xghIiIislgMQkRERGSxGISIiIjIYjEIERERkcViECIiIiKLxSBEREREFotBiIiIiCwWgxARURPs2bMHgiCgoKBA6lKIyIgYhIiIiMhiMQgRERGRxWIQIiKzIIoiFixYgM6dO8POzg5hYWH473//C+DWZavNmzcjLCwMtra2GDx4ME6dOmVwjvj4eISGhkKhUCAwMBALFy40eLyiogKvvfYa/P39oVAo0K1bN6xYscKgzbFjxzBgwADY29sjKioK586da903TkStikGIiMzC22+/jR9//BHLly/H6dOn8corr+Cpp55CQkKCvs3f//53fP755zhy5Ag8PT3xwAMPoKqqCoAuwEyePBl/+ctfcOrUKbz//vt45513EBcXp3/+1KlTsXr1aixZsgQpKSn45ptv4OjoaFDHW2+9hYULF+Lo0aOwtrbGM8880ybvn4haBxddJSKTV1JSAnd3d+zatQuRkZH648899xxKS0sxc+ZMDB8+HKtXr0ZMTAwAIC8vD35+foiLi8PkyZPx5JNP4ubNm9i+fbv++a+99ho2b96M06dP4/z58wgODsaOHTswcuTIOjXs2bMHw4cPx86dOzFixAgAwJYtWzB+/HiUlZXB1ta2lT8FImoN7BEiIpN35swZlJeXY9SoUXB0dNRvK1euxMWLF/XtaockV1dXBAcHIyUlBQCQkpKCIUOGGJx3yJAhuHDhAjQaDZKTk2FlZYV777230Vr69Omj/93HxwcAkJ2dfdfvkYikYS11AUREd6LVagEAmzdvRseOHQ0eUygUBmHodoIgANCNMar5vUbtDnE7O7sm1WJjY1Pn3DX1EZH5YY8QEZm8kJAQKBQKpKWloWvXrgabv7+/vt3Bgwf1v+fn5+P8+fPo0aOH/hz79+83OO+BAwfQvXt3WFlZoXfv3tBqtQZjjoio/WOPEBGZPCcnJ8ybNw+vvPIKtFothg4dCpVKhQMHDsDR0REBAQEAgA8//BBubm7w8vLCW2+9BXd3d0yaNAkA8Oqrr2LgwIH46KOPEBMTg8TERCxduhTLli0DAAQGBmLatGl45plnsGTJEoSFheHq1avIzs7G5MmTpXrrRNTKGISIyCx89NFH8PT0RGxsLC5dugQXFxf069cPb775pv7S1KefforZs2fjwoULCAsLw6ZNmyCXywEA/fr1w9q1a/Huu+/io48+go+PDz788ENMnz5d/xrLly/Hm2++iRdeeAG5ubno1KkT3nzzTSneLhG1Ed41RkRmr+aOrvz8fLi4uEhdDhGZEY4RIiIiIovFIEREREQWi5fGiIiIyGKxR4iIiIgsFoMQERERWSwGISIiIrJYDEJERERksRiEiIiIyGIxCBEREZHFYhAiIiIii8UgRERERBaLQYiIiIgs1v8DfD4gfvaG6scAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "890d17f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 354ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        93\n",
      "           1       1.00      0.99      0.99       195\n",
      "\n",
      "    accuracy                           0.99       288\n",
      "   macro avg       0.99      0.99      0.99       288\n",
      "weighted avg       0.99      0.99      0.99       288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred>=0.5).astype(int)\n",
    "print(classification_report(y_mix_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37640eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 369ms/step - accuracy: 0.9945 - loss: 0.2370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23244601488113403, 0.9930555820465088]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_mix_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
