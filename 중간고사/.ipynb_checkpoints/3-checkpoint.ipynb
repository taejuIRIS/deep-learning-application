{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f9aaab0",
   "metadata": {},
   "source": [
    "다음 데이터 세트를 이용하여 다이아몬드 가격예측(회귀)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv\" diamonds = pd.read_csv(url)\n",
    "\n",
    "ML (RF, DT, LR) 수행\n",
    "\n",
    "Dense layer만 이용 FNCC 구현\n",
    "\n",
    "순환 데이터 변환후 CNN 구현\n",
    "\n",
    "각 단계별로 수행완료후\n",
    "\n",
    "검사받은 이후에 다음 단계 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab6522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468556a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "diamonds = pd.read_csv( \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/diamonds.csv\")\n",
    "diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c55046",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3dedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['cut'] = label_encoder.fit_transform(df['cut']) # label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e80f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['color'] = label_encoder.fit_transform(df['color']) # label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50269130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['clarity'] = label_encoder.fit_transform(df['clarity']) # label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2cef3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87054bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc10e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블 개수 확인 (숫자)\n",
    "df['cut'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebe0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#결측치 확인\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e1efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outcome만 제거하고 x를 만든다\n",
    "X=df.drop('price',axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be53cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#레이블만 남겨둔다.\n",
    "y=df['price']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38effca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14653bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data (CNN and LSTM models often perform better with normalized data)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bedea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        # 입력 시퀀스는 마지막 열을 제외한 값\n",
    "        seq_x = sequences[i:end_ix, :-1]\n",
    "        # 출력 y는 마지막 열의 평균값\n",
    "        seq_y = np.mean(sequences[i:end_ix, -1])\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c54c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.c_[X_train, y_train]\n",
    "test_set = np.c_[X_test, y_test]\n",
    "\n",
    "X_train, y_train = split_sequences(train_set, 5)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "X_test, y_test = split_sequences(test_set, 5)\n",
    "print(X_test.shape, y_test.shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터를 (샘플 수, 타임스텝 수, 1) 형태로 변환\n",
    "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the CNN model for regression\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add 1D Convolutional layers\n",
    "model.add(layers.Conv1D(64, kernel_size=2, activation='relu', input_shape=(X_test_scaled.shape[1], 1)))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Conv1D(32, kernel_size=2, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten the output and add Dense layers for regression\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1))  # Output layer for regression\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
